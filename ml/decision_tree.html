<!DOCTYPE html>

<html lang="zh-CN" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1. 决策树 &#8212; Machine Learning Fundation 1.0 文档</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css?v=279e0f84" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="../_static/documentation_options.js?v=f115507d"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="../_static/mathjax/tex-chtml.js"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">
import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.esm.min.mjs";
window.addEventListener("load", () => mermaid.run());
</script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="2. 数据降维" href="dimension_reduce.html" />
    <link rel="prev" title="4. 计算学习理论" href="../base/calc_theory.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="Related">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="总索引"
             accesskey="I">索引</a></li>
        <li class="right" >
          <a href="dimension_reduce.html" title="2. 数据降维"
             accesskey="N">下一页</a> |</li>
        <li class="right" >
          <a href="../base/calc_theory.html" title="4. 计算学习理论"
             accesskey="P">上一页</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Machine Learning Fundation 1.0 文档</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">1. </span>决策树</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1><span class="section-number">1. </span>决策树<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h1>
<p>  <strong>决策树</strong>是一种模拟人决策过程的树形结构。例如：如果有以下一段对话，</p>
<blockquote>
<div><p>女儿：多大年纪了？<br>
母亲：26。<br>
女儿：长的帅不帅？<br>
母亲：挺帅的。<br>
女儿：收入高不？<br>
母亲：不算很高，中等情况。<br>
女儿：是公务员不？<br>
母亲：是，在税务局上班呢。<br>
女儿：那好，我去见见。<br></p>
</div></blockquote>
<p>上述对话体现了人类做出见/不见决策的一个过程。根据对话的顺序，该决策过程可以用下图来刻画。</p>
<figure class="align-center" id="id5">
<pre  class="mermaid">
        %%{
    init: {
        'theme':'base',
        'themeVariables': {
            'fontSize': 8px
        }
    }
}%%
flowchart LR
  id1((年龄)) -- &lt;=30--&gt; id2((长相))
  id1 -- &gt;30 --&gt; id3[不见]
  id2 -- 帅 --&gt; id4((收入))
  id2 -- 不帅 --&gt; id5[不见]
  id4 -- 高 --&gt; id6[见]
  id4 -- 中 --&gt; id7((公务员))
  id4 -- 低 --&gt; id8[不见]
  id7 -- 是 --&gt; id9[见]
  id7 -- 不是 --&gt; id10[不见]
 
    </pre><figcaption>
<p><span class="caption-text">Fig 1. 决策过程模拟树。</span><a class="headerlink" href="#id5" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>  <strong>决策树在构建过程中有个基本问题需要解答</strong>。如上图所示，为什么选择年龄做为第1个分裂的结点而不是其它特征？也就是如何确定分裂特征的顺序？这一问题也称为<strong>特征选择</strong>问题。</p>
<p>  依据特征选择策略的不同，决策树算法大至有ID3,C4.5,CART等不同的决策树构建算法。这些算法的基本流程框架如下所示：</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>决策树学习算法基本框架</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>输入</strong>: 训练集<span class="math notranslate nohighlight">\(D=\{(\pmb{x}_1,y_1),(\pmb{x}_2,y_2),...,(\pmb{x}_m,y_m)\}\)</span>，属性集<span class="math notranslate nohighlight">\(A=\{a_1,a_2,...,a_d\}\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>输出</strong>: 以<em>root</em>为根的一棵决策树</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>过程</strong>: <em>decisionTree(D,A)</em></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>1: 生成结点<em>root</em> <br>2: <strong>if</strong>(<span class="math notranslate nohighlight">\(D\)</span>中样本属于同一类别<span class="math notranslate nohighlight">\(C\)</span>){ <br>3:    return; <br>4: }<br>5: <strong>if</strong>(<span class="math notranslate nohighlight">\(A=\emptyset\)</span> or <span class="math notranslate nohighlight">\(D\)</span>中样本在属性<span class="math notranslate nohighlight">\(A\)</span>取值一致){<br>6:   将root标记为叶结点，类别为<span class="math notranslate nohighlight">\(D\)</span>中样本数最多的类; return;<br>7: }<br>8: 根据属性挑选规则，在属性集<span class="math notranslate nohighlight">\(A\)</span>中挑选最优属性<span class="math notranslate nohighlight">\(a\)</span>;<br>9: <strong>for</strong>(<span class="math notranslate nohighlight">\(a\)</span>的每一个属性值<span class="math notranslate nohighlight">\(a^v\)</span>){<br>10:  为root生成一个分支结点，该结点的样本集<span class="math notranslate nohighlight">\(D_v\)</span>为<span class="math notranslate nohighlight">\(a==a^v\)</span>的所有样本;<br>11:  <strong>if</strong>(<span class="math notranslate nohighlight">\(D_v\)</span>为空){<br>12:    将分支结点(子结点)标记为叶结点;类别为<span class="math notranslate nohighlight">\(D\)</span>中样本最多的类别; return;<br>13:  <strong>else</strong><br>14:    以dicisionTree(<span class="math notranslate nohighlight">\(D_v\)</span>,A-<span class="math notranslate nohighlight">\(\{a\})\)</span>为分支结点继续分裂;<br>15:  }<br>16:}</p></td>
</tr>
</tbody>
</table>
<section id="id3">
<h2><span class="section-number">1.1. </span>ID3<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h2>
<p>  ID3（Iterative Dichotomiser 3）算法是一种经典的决策树学习算法，由Ross Quinlan于1986年提出。该算法的主要目的是通过构建一个决策树模型来对样本数据进行分类。ID3算法的核心思想是基于<strong>信息增益</strong>（Information Gain）来选择最佳的属性作为决策树的节点，以此来实现对数据的划分。</p>
<p>  <strong>定义（信息熵）</strong>. 假设有离散随机变量（连续型同样适用，只是公式的表示形式不一样）<span class="math notranslate nohighlight">\(X\)</span>其取值概率分别为<span class="math notranslate nohighlight">\(\{(x_1,p_1),...,(x_n,p_n)\}\)</span>(s.t.<span class="math notranslate nohighlight">\(\sum_i p_i=1\)</span>)，则该随机变量的信息熵(不确定性)为，</p>
<div class="math notranslate nohighlight" id="equation-entropy-def">
<span class="eqno">(1)<a class="headerlink" href="#equation-entropy-def" title="Link to this equation">¶</a></span>\[
\textrm{H}(X)=-\sum_i^n p_i\log p_i
\]</div>
<p>  <strong>定义（条件熵）</strong>. 假设有离散随机变量<span class="math notranslate nohighlight">\(X,Y\)</span>，则条件熵为(记<span class="math notranslate nohighlight">\(p(y_i)\triangleq P(Y=y_i)\)</span>)，</p>
<div class="math notranslate nohighlight" id="equation-cond-entropy">
<span class="eqno">(2)<a class="headerlink" href="#equation-cond-entropy" title="Link to this equation">¶</a></span>\[\begin{split}
      \begin{split}
        \textrm{H}(X|Y)&amp;=\sum_{y_i\in Y}p(y_i)\textrm{H}(X|y_i)\\
        &amp;=-\sum_{y_i\in Y}p(y_i)\sum_{x_j\in X}P(x_j|y_i)\log P(x_j|y_i)
      \end{split}
\end{split}\]</div>
<p>  <strong>定义（信息增益）</strong>. 随机变量<span class="math notranslate nohighlight">\(X\)</span>的信息熵与条件熵<span class="math notranslate nohighlight">\(X|Y\)</span>的差异即为信息增益，即</p>
<div class="math notranslate nohighlight" id="equation-information-gain">
<span class="eqno">(3)<a class="headerlink" href="#equation-information-gain" title="Link to this equation">¶</a></span>\[
        \textrm{IG}(X,Y)=\textrm{H}(X)-\textrm{H}(X|Y)
\]</div>
<section id="id2">
<h3><span class="section-number">1.1.1. </span>ID3构建算法<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<p>  ID3构建算法只需要对上一节的决策树学习算法的第8行进行修改，即为ID3学习算法。</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>ID3决策树学习算法基本框架</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>输入</strong>: 训练集<span class="math notranslate nohighlight">\(D=\{(\pmb{x}_1,y_1),(\pmb{x}_2,y_2),...,(\pmb{x}_m,y_m)\}\)</span>，属性集<span class="math notranslate nohighlight">\(A=\{a_1,a_2,...,a_d\}\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>输出</strong>: 以<em>root</em>为根的一棵决策树</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>过程</strong>: <em>decisionTree(D,A)</em></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>1: 生成结点<em>root</em> <br>2: <strong>if</strong>(<span class="math notranslate nohighlight">\(D\)</span>中样本属于同一类别<span class="math notranslate nohighlight">\(C\)</span>){ <br>3:    return; <br>4: }<br>5: <strong>if</strong>(<span class="math notranslate nohighlight">\(A=\emptyset\)</span> or <span class="math notranslate nohighlight">\(D\)</span>中样本在属性<span class="math notranslate nohighlight">\(A\)</span>取值一致){<br>6:   将root标记为叶结点，类别为<span class="math notranslate nohighlight">\(D\)</span>中样本数最多的类; return;<br>7: }<br>8: <strong>计算所有属性的信息增益，在属性集<span class="math notranslate nohighlight">\(A\)</span>中挑选最大增益属性</strong><span class="math notranslate nohighlight">\(a\)</span>;<br>9: <strong>for</strong>(<span class="math notranslate nohighlight">\(a\)</span>的每一个属性值<span class="math notranslate nohighlight">\(a^v\)</span>){<br>10:  为root生成一个分支结点，该结点的样本集<span class="math notranslate nohighlight">\(D_v\)</span>为<span class="math notranslate nohighlight">\(a==a^v\)</span>的所有样本;<br>11:  <strong>if</strong>(<span class="math notranslate nohighlight">\(D_v\)</span>为空){<br>12:    将分支结点(子结点)标记为叶结点;类别为<span class="math notranslate nohighlight">\(D\)</span>中样本最多的类别; return;<br>13:  <strong>else</strong><br>14:    以dicisionTree(<span class="math notranslate nohighlight">\(D_v\)</span>,A-<span class="math notranslate nohighlight">\(\{a\})\)</span>为分支结点继续分裂;<br>15:  }<br>16:}</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id4">
<h3><span class="section-number">1.1.2. </span>ID3应用案例<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h3>
<p>  应用ID3算法构建一棵决策树，该案例使用UCI数据集weather，内容如下表所示：</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p><strong>outlook</strong></p></th>
<th class="head text-center"><p><strong>temperature</strong></p></th>
<th class="head text-center"><p><strong>humidity</strong></p></th>
<th class="head text-center"><p><strong>windy</strong></p></th>
<th class="head text-center"><p><strong>play</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>sunny</p></td>
<td class="text-center"><p>hot</p></td>
<td class="text-center"><p>high</p></td>
<td class="text-center"><p>FALSE</p></td>
<td class="text-center"><p>no</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>sunny</p></td>
<td class="text-center"><p>hot</p></td>
<td class="text-center"><p>high</p></td>
<td class="text-center"><p>TRUE</p></td>
<td class="text-center"><p>no</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>overcast</p></td>
<td class="text-center"><p>hot</p></td>
<td class="text-center"><p>high</p></td>
<td class="text-center"><p>FALSE</p></td>
<td class="text-center"><p>yes</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>rainy</p></td>
<td class="text-center"><p>mild</p></td>
<td class="text-center"><p>high</p></td>
<td class="text-center"><p>FALSE</p></td>
<td class="text-center"><p>yes</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>rainy</p></td>
<td class="text-center"><p>cool</p></td>
<td class="text-center"><p>normal</p></td>
<td class="text-center"><p>FALSE</p></td>
<td class="text-center"><p>yes</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>rainy</p></td>
<td class="text-center"><p>cool</p></td>
<td class="text-center"><p>normal</p></td>
<td class="text-center"><p>TRUE</p></td>
<td class="text-center"><p>no</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>overcast</p></td>
<td class="text-center"><p>cool</p></td>
<td class="text-center"><p>normal</p></td>
<td class="text-center"><p>TRUE</p></td>
<td class="text-center"><p>yes</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>sunny</p></td>
<td class="text-center"><p>mild</p></td>
<td class="text-center"><p>high</p></td>
<td class="text-center"><p>FALSE</p></td>
<td class="text-center"><p>no</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>sunny</p></td>
<td class="text-center"><p>cool</p></td>
<td class="text-center"><p>normal</p></td>
<td class="text-center"><p>FALSE</p></td>
<td class="text-center"><p>yes</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>rainy</p></td>
<td class="text-center"><p>mild</p></td>
<td class="text-center"><p>normal</p></td>
<td class="text-center"><p>FALSE</p></td>
<td class="text-center"><p>yes</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>sunny</p></td>
<td class="text-center"><p>mild</p></td>
<td class="text-center"><p>normal</p></td>
<td class="text-center"><p>TRUE</p></td>
<td class="text-center"><p>yes</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>overcast</p></td>
<td class="text-center"><p>mild</p></td>
<td class="text-center"><p>high</p></td>
<td class="text-center"><p>TRUE</p></td>
<td class="text-center"><p>yes</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>overcast</p></td>
<td class="text-center"><p>hot</p></td>
<td class="text-center"><p>normal</p></td>
<td class="text-center"><p>FALSE</p></td>
<td class="text-center"><p>yes</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>rainy</p></td>
<td class="text-center"><p>mild</p></td>
<td class="text-center"><p>high</p></td>
<td class="text-center"><p>TRUE</p></td>
<td class="text-center"><p>no</p></td>
</tr>
</tbody>
</table>
<div class="dropdown admonition">
<p class="admonition-title"><strong>计算过程</strong></p>
<br>
<p><strong>第1步. 根据信息增益选择分裂属性，对数据集D进行分裂</strong>。</p>
<p>  <strong>1.1 计算分类属性<code class="docutils literal notranslate"><span class="pre">play</span></code>的信息熵</strong>。</p>
<div class="math notranslate nohighlight">
\[
\textrm{H(play)}=-\frac{5}{14}\log\frac{5}{14}-\frac{9}{14}\log\frac{9}{14}=0.94
\]</div>
<p>  <strong>1.2 计算分类属性对所有其它属性的条件熵</strong>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\textrm{H(play|outlook)}&amp;=-\frac{5}{14}\left(\frac25\log\frac25+\frac35\log\frac35\right)-\frac{4}{14}\left(1\log 1+0\log 0\right)-\frac{5}{14}\left(\frac25\log\frac25+\frac35\log\frac35\right)=0.69\\
\textrm{H(play|temperatur)}&amp;=-\frac{4}{14}\left(\frac12\log\frac12+\frac12\log\frac12\right)-\frac{6}{14}\left(\frac46\log\frac46 +\frac26\log\frac26\right)-\frac{4}{14}\left(\frac13\log\frac13+\frac23\log\frac23\right)=0.91\\
\textrm{H(play|humidity)}&amp;=-\frac{7}{14}\left(\frac37\log\frac37+\frac47\log\frac47\right)-\frac{7}{14}\left(\frac17\log\frac17 +\frac67\log\frac67\right)=0.78\\
\textrm{H(play|windy)}&amp;=-\frac{6}{14}\left(\frac36\log\frac36+\frac36\log\frac36\right)-\frac{8}{14}\left(\frac68\log\frac68 +\frac28\log\frac28\right)=0.89\\
\end{split}
\end{split}\]</div>
<p>  <strong>1.3 计算所有属性的信息增益</strong>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\textrm{IG(play,outlook)}&amp;=\textrm{H(play)}-\textrm{H(play|outlook)}=0.24\\
\textrm{IG(play,temperatur)}&amp;=\textrm{H(play)}-\textrm{H(play|temperatur)}=0.02\\
\textrm{IG(play,humidity)}&amp;=\textrm{H(play)}-\textrm{H(play|humidity)}=0.15\\
\textrm{IG(play,windy)}&amp;=\textrm{H(play)}-\textrm{H(play|windy)}=0.04\\
\end{split}
\end{split}\]</div>
<p>  <strong>1.4 选择信息增益最大的属性<code class="docutils literal notranslate"><span class="pre">outlook</span></code>分裂</strong>。</p>
<p>  当<code class="docutils literal notranslate"><span class="pre">outlook=overcast</span></code>时，该子集的决策属性值一致，都为<code class="docutils literal notranslate"><span class="pre">yes</span></code>，因此不必对该分支继续分裂；相反地，D1·D2还需进一步分裂。分裂结果如下图所示：</p>
<figure class="align-center" id="id6">
<pre  class="mermaid">
        %%{
    init: {
        'theme':'base',
        'themeVariables': {
            'fontSize': 8px
        }
    }
}%%
flowchart LR
  id1((outlook)) -- overcast --&gt; id2[YES]
  id1 -- rainy --&gt; id3[(D1)]
  id1 -- sunny --&gt; id4[(D2)]
 
    </pre><figcaption>
<p><span class="caption-text">Fig 2. 根据属性<em>outlook</em>分裂数据集。</span><a class="headerlink" href="#id6" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p><strong>第2步. 根据信息增益选择分裂属性，对数据集D1进行分裂</strong>。</p>
<p>  <strong>2.1 计算分类属性<code class="docutils literal notranslate"><span class="pre">play</span></code>的信息熵</strong>。第1步已计算，直接使用上一步的结果。</p>
<p>  <strong>2.2 计算分类属性对所有未选择的属性的条件熵</strong>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\textrm{H(play|temperatur)}&amp;=-\frac{2}{5}\left(\frac12\log\frac12+\frac12\log\frac12\right)-\frac{3}{5}\left(\frac13\log\frac13 +\frac23\log\frac23\right)=0.951\\
\textrm{H(play|humidity)}&amp;=-\frac{2}{5}\left(\frac12\log\frac12+\frac47\log\frac47\right)-\frac{3}{5}\left(\frac13\log\frac13 +\frac23\log\frac23\right)=0.951\\
\textrm{H(play|windy)}&amp;=-\frac{2}{5}\left(1\log 1+0 \log 0\right)-\frac{3}{5}\left(1\log 1+0 \log 0\right)=0.00\\
\end{split}
\end{split}\]</div>
<p>  <strong>2.3 计算所有属性的信息增益</strong>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\textrm{IG(play,temperatur)}&amp;=\textrm{H(play)}-\textrm{H(play|temperatur)}=0.02\\
\textrm{IG(play,humidity)}&amp;=\textrm{H(play)}-\textrm{H(play|humidity)}=0.02\\
\textrm{IG(play,windy)}&amp;=\textrm{H(play)}-\textrm{H(play|windy)}=0.97\\
\end{split}
\end{split}\]</div>
<p>  <strong>2.4 选择信息增益最大的属性<code class="docutils literal notranslate"><span class="pre">windy</span></code>分裂</strong>。</p>
<p>  当<code class="docutils literal notranslate"><span class="pre">windy=yes</span></code>时，该子集的决策属性值一致，都为<code class="docutils literal notranslate"><span class="pre">no</span></code>；当<code class="docutils literal notranslate"><span class="pre">windy=no</span></code>时，该子集的决策属性值一致，都为<code class="docutils literal notranslate"><span class="pre">yes</span></code>，因此不必对所有分支继续分裂。至此，D1分裂结束。分裂结果如下图所示：</p>
<figure class="align-center" id="id7">
<pre  class="mermaid">
        %%{
    init: {
        'theme':'base',
        'themeVariables': {
            'fontSize': 8px
        }
    }
}%%
flowchart LR
  id1((outlook)) -- overcast --&gt; id2[YES]
  id1 -- rainy --&gt; id3[(windy)]
  id1 -- sunny --&gt; id4[(D2)]
  id3 -- yes --&gt; id5[NO]
  id3 -- no --&gt; id6[YES]
 
    </pre><figcaption>
<p><span class="caption-text">Fig 3. 根据属性<em>windy</em>分裂数据集D1。</span><a class="headerlink" href="#id7" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p><strong>第3步. 根据信息增益选择分裂属性，对数据集D2进行分裂</strong>。</p>
<p>  <strong>3.1 计算分类属性<code class="docutils literal notranslate"><span class="pre">play</span></code>的信息熵</strong>。第1步已计算，直接使用上一步的结果。</p>
<p>  <strong>3.2 计算分类属性对所有未选择的属性的条件熵</strong>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\textrm{H(play|temperatur)}&amp;=-\frac{2}{5}\left(1\log 1+0 \log 0\right)-\frac{2}{5}\left(\frac12\log\frac12 +\frac12\log\frac12\right)-\frac{1}{5}\left(1\log 1+0 \log 0 \right)=0.4\\
\textrm{H(play|humidity)}&amp;=-\frac{2}{5}\left(1\log 1+0 \log 0\right)-\frac{3}{5}\left(1\log 1+0 \log 0\right)=0.0\\
\textrm{H(play|windy)}&amp;=-\frac{2}{5}\left(\frac12\log\frac12 +\frac12\log\frac12\right)-\frac{3}{5}\left(\frac13\log\frac13 +\frac23\log\frac23\right)=0.95\\
\end{split}
\end{split}\]</div>
<p>  <strong>3.3 计算所有属性的信息增益</strong>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\textrm{IG(play,temperatur)}&amp;=\textrm{H(play)}-\textrm{H(play|temperatur)}=0.57\\
\textrm{IG(play,humidity)}&amp;=\textrm{H(play)}-\textrm{H(play|humidity)}=0.97\\
\textrm{IG(play,windy)}&amp;=\textrm{H(play)}-\textrm{H(play|windy)}=0.02\\
\end{split}
\end{split}\]</div>
<p>  <strong>3.4 选择信息增益最大的属性<code class="docutils literal notranslate"><span class="pre">humidity</span></code>分裂</strong>。</p>
<p>  当<code class="docutils literal notranslate"><span class="pre">humidity=high</span></code>时，该子集的决策属性值一致，都为<code class="docutils literal notranslate"><span class="pre">no</span></code>；当<code class="docutils literal notranslate"><span class="pre">humidity=normal</span></code>时，该子集的决策属性值一致，都为<code class="docutils literal notranslate"><span class="pre">yes</span></code>，因此不必对所有分支继续分裂。至此，D2分裂结束。分裂结果如下图所示：</p>
<figure class="align-center" id="id8">
<pre  class="mermaid">
        %%{
    init: {
        'theme':'base',
        'themeVariables': {
            'fontSize': 8px
        }
    }
}%%
flowchart LR
  id1((outlook)) -- overcast --&gt; id2[YES]
  id1 -- rainy --&gt; id3[(windy)]
  id1 -- sunny --&gt; id4[(humidity)]
  id3 -- yes --&gt; id5[NO]
  id3 -- no --&gt; id6[YES]
  id4 -- high --&gt; id7[NO]
  id4 -- normal --&gt; id8[YES]
    </pre><figcaption>
<p><span class="caption-text">Fig 4. 根据属性<em>humidity</em>分裂数据集D2。</span><a class="headerlink" href="#id8" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</div>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../index.html">目录</a></h3>
    <ul>
<li><a class="reference internal" href="#">1. 决策树</a><ul>
<li><a class="reference internal" href="#id3">1.1. ID3</a><ul>
<li><a class="reference internal" href="#id2">1.1.1. ID3构建算法</a></li>
<li><a class="reference internal" href="#id4">1.1.2. ID3应用案例</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>上一主题</h4>
    <p class="topless"><a href="../base/calc_theory.html"
                          title="上一章"><span class="section-number">4. </span>计算学习理论</a></p>
  </div>
  <div>
    <h4>下一主题</h4>
    <p class="topless"><a href="dimension_reduce.html"
                          title="下一章"><span class="section-number">2. </span>数据降维</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/ml/decision_tree.md.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">快速搜索</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="提交" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="Related">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="总索引"
             >索引</a></li>
        <li class="right" >
          <a href="dimension_reduce.html" title="2. 数据降维"
             >下一页</a> |</li>
        <li class="right" >
          <a href="../base/calc_theory.html" title="4. 计算学习理论"
             >上一页</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Machine Learning Fundation 1.0 文档</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">1. </span>决策树</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; 版权所有 2022-2024, SSPUIIP.
      由 <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3创建。
    </div>
  </body>
</html>