<!DOCTYPE html>

<html lang="zh-CN" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5. 贝叶斯分类 &#8212; Machine Learning Fundation 1.0 文档</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css?v=279e0f84" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="../_static/documentation_options.js?v=f115507d"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="../_static/mathjax/tex-chtml.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="6. 神经网络" href="neuro_network.html" />
    <link rel="prev" title="4. 概率图模型" href="PGM.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="Related">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="总索引"
             accesskey="I">索引</a></li>
        <li class="right" >
          <a href="neuro_network.html" title="6. 神经网络"
             accesskey="N">下一页</a> |</li>
        <li class="right" >
          <a href="PGM.html" title="4. 概率图模型"
             accesskey="P">上一页</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Machine Learning Fundation 1.0 文档</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">5. </span>贝叶斯分类</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1><span class="section-number">5. </span>贝叶斯分类<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h1>
<section id="id2">
<h2><span class="section-number">5.1. </span>贝叶斯决策<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h2>
<blockquote>
<div><p>贝叶斯决策论是概率框架下决策的基本方法。</p>
<p class="attribution">—Bayesian decision theory</p>
</div></blockquote>
<p>  假设有类型标记<span class="math notranslate nohighlight">\(\mathcal{Y}=\{c_1,...,c_n\}\)</span>，在决策过程中类别<span class="math notranslate nohighlight">\(c_j\)</span>的样本划分为类别<span class="math notranslate nohighlight">\(c_i\)</span>所产生的<strong>损失</strong>记为<span class="math notranslate nohighlight">\(\lambda_{ij}\)</span>，则将样本<span class="math notranslate nohighlight">\(\pmb{x}\)</span>分类为<span class="math notranslate nohighlight">\(c_i\)</span>产生的损失期望(expected loss)，也称为<strong>条件风险</strong>，</p>
<div class="math notranslate nohighlight" id="equation-expected-loss">
<span class="eqno">(1)<a class="headerlink" href="#equation-expected-loss" title="Link to this equation">¶</a></span>\[
R(c_i|\pmb{x})=\sum_{j}^N \lambda_{ij}\cdot P(c_j|\pmb{x})
\]</div>
<p>其中，<span class="math notranslate nohighlight">\(P(c_j|\pmb{x})\)</span>为类别标记<span class="math notranslate nohighlight">\(c_j\)</span>的<strong>后验概率</strong>。分类的任务是寻找一个<strong>最优分类映射</strong><span class="math notranslate nohighlight">\(h:\mathcal{x}\rightarrow \mathcal{Y}\)</span>，从而最小化<strong>总体风险</strong>，</p>
<div class="math notranslate nohighlight" id="equation-total-risk">
<span class="eqno">(2)<a class="headerlink" href="#equation-total-risk" title="Link to this equation">¶</a></span>\[
R(h)=\mathbb{E}_{\pmb{x}}\{R[h(\pmb{x})|\pmb{x}]\}
\]</div>
<p>如果<span class="math notranslate nohighlight">\(h\)</span>对每个样本都能最小化条件风险<a class="reference internal" href="#equation-expected-loss">(1)</a><span class="math notranslate nohighlight">\(R[h(\pmb{x}|\pmb{x}]\)</span>，则总体风险<a class="reference internal" href="#equation-total-risk">(2)</a>也能最小化。因此就有了<strong>贝叶斯判定准则</strong>：</p>
<blockquote>
<div><p>为了最小化总体风险，对每个样本都选择能使条件风险<a class="reference internal" href="#equation-expected-loss">(1)</a>最小的类别标记。</p>
<p class="attribution">—Bayes decision rule</p>
</div></blockquote>
<p>也就是，</p>
<div class="math notranslate nohighlight" id="equation-optimal-function">
<span class="eqno">(3)<a class="headerlink" href="#equation-optimal-function" title="Link to this equation">¶</a></span>\[
h^*(\pmb{x})=\arg\min\limits_{c\in\mathcal{Y}} R(c|\pmb{x})
\]</div>
<p>此时，<span class="math notranslate nohighlight">\(h^*\)</span>称为<strong>贝叶斯最优分类器</strong>，对应的总体风险<span class="math notranslate nohighlight">\(R(h^*)\)</span>称为<strong>贝叶斯风险</strong>。</p>
</section>
<section id="id3">
<h2><span class="section-number">5.2. </span>朴素贝叶斯分类器<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h2>
<p>  贝叶斯公式<a class="reference internal" href="#equation-bayes-formula">(4)</a>估计后验概率的主要困难在于<font color="blue">类条件概率<span class="math notranslate nohighlight">\(P(\pmb{x}|c)\)</span>是样本的所有属性上的联合概率</font>，难以从有限的训练样本直接估计得到，</p>
<div class="math notranslate nohighlight" id="equation-bayes-formula">
<span class="eqno">(4)<a class="headerlink" href="#equation-bayes-formula" title="Link to this equation">¶</a></span>\[
\underbrace{P(y=c|\pmb{x})}_{\mathrm{posterior}}=\frac{\overbrace{P(y=c)}^{\mathrm{prior}}\times\overbrace{P(\pmb{x}|y=c)}^{\mathrm{likelihood}}}{\underbrace{p(\pmb{x})}_{\mathrm{evidence}}}
\]</div>
<p>  对于这一问题，假设所有属性相互独立，则类条件概率可以拆分为如下形式，</p>
<div class="math notranslate nohighlight" id="equation-class-condition">
<span class="eqno">(5)<a class="headerlink" href="#equation-class-condition" title="Link to this equation">¶</a></span>\[
P(\pmb{x}|y=c)=\prod_{j=1}^d P(x_j|y=c)
\]</div>
<p>相应地，贝叶斯判定准则式<a class="reference internal" href="#equation-optimal-function">(3)</a>可以改写为，</p>
<div class="math notranslate nohighlight" id="equation-naive-bayes-target">
<span class="eqno">(6)<a class="headerlink" href="#equation-naive-bayes-target" title="Link to this equation">¶</a></span>\[
h_{nb}(\pmb{x})=\arg\max\limits_{c\in\mathcal{Y}}P(y=c)\prod_{j=1}^d P(x_j|y=c)
\]</div>
<p>上式<a class="reference internal" href="#equation-naive-bayes-target">(6)</a>即为<strong>朴素贝叶斯分类器</strong>。训练该模型就是使用训练集<span class="math notranslate nohighlight">\(D\)</span>来估计先验概率<span class="math notranslate nohighlight">\(P(c)\)</span>和类条件概率<span class="math notranslate nohighlight">\(P(x_i|c)\)</span>的参数。</p>
<p>  （一）<strong>模型训练</strong></p>
<p>  单个样本的似然函数为，</p>
<div class="math notranslate nohighlight" id="equation-single-sample-likelihood">
<span class="eqno">(7)<a class="headerlink" href="#equation-single-sample-likelihood" title="Link to this equation">¶</a></span>\[\begin{split}
\begin{split}
p(\pmb{x}_i,y_i|\pmb{\theta})&amp;=p(y=y_i|\pmb{\pi})\prod_{j=1}^D p(\pmb{x}_i|y=y_i)\\
\end{split}
\end{split}\]</div>
<p>可以得到所有样本的对数似然函数，</p>
<div class="math notranslate nohighlight" id="equation-dataset-log-likelihood">
<span class="eqno">(8)<a class="headerlink" href="#equation-dataset-log-likelihood" title="Link to this equation">¶</a></span>\[\begin{split}
\begin{split}
\ln p(\mathcal{D}|\pmb{\theta})&amp;= \sum_{i=1}^N \ln p(\pmb{x}_i,y_i|\pmb{\theta})\\
&amp;=\sum_{c=1}^C N_c\ln \pi_c +\sum_{j=1}^D\sum_{c=1}^C\sum_{i:y_i=c}\ln p(x_{ij}|\theta_{jc}),\quad N_c\triangleq\sum_{i=1}^N \mathbb{I}(y_i=c)
\end{split}
\end{split}\]</div>
<p>  对式<a class="reference internal" href="#equation-dataset-log-likelihood">(8)</a>求偏导，并令其等于0，可得到参数的估值，</p>
<div class="math notranslate nohighlight" id="equation-pic-hat">
<span class="eqno">(9)<a class="headerlink" href="#equation-pic-hat" title="Link to this equation">¶</a></span>\[
\begin{split}
\hat{\pi}_c=\frac{N_c}{N}
\end{split}
\]</div>
<p>  <span class="math notranslate nohighlight">\(\theta_{jc}\)</span>的估值依赖于具体的特征类型所使用的分布。<strong>以<span class="math notranslate nohighlight">\(x_i|y\sim \text{Ber}(\theta_{jc})\)</span>为例</strong>，</p>
<div class="math notranslate nohighlight" id="equation-thetajc-hat">
<span class="eqno">(10)<a class="headerlink" href="#equation-thetajc-hat" title="Link to this equation">¶</a></span>\[
\hat{\theta}_{jc}=\frac{N_{jc}}{N_c}
\]</div>
<p>  通过对上述参数的求解可以看出，该模型的训练非常容易实现，且模型训练时间复杂度仅为<span class="math notranslate nohighlight">\(O(ND)\)</span>。处理混合类型特征也相对容易实现。最大似然估计的问题是过拟合。例如，假设特征<span class="math notranslate nohighlight">\(j\)</span>的值（有且只有一个）在所有类别中出现，则可以得到<span class="math notranslate nohighlight">\(\hat{\theta}_{jc}=1\)</span>。当我们遇到一个不含有此特征值的样本时，算法将会失效，因为对于所有类来说<span class="math notranslate nohighlight">\(p(y=c|\pmb{x},\hat{\theta})=0\)</span>。一个简单的办法是贝叶斯化。</p>
<p>  （二）<strong>贝叶斯naive Bayes</strong></p>
<p>  使用一个因子化的先验，</p>
<div class="math notranslate nohighlight" id="equation-conjugate-prior-bayes">
<span class="eqno">(11)<a class="headerlink" href="#equation-conjugate-prior-bayes" title="Link to this equation">¶</a></span>\[
p(\pmb{\theta})=p(\pmb{\pi})\prod_{j=1}^D\prod_{c=1}^C p(\theta_{jc}),\quad \pmb{\pi}\sim \text{Dir}(\pmb{\alpha}),\theta_{jc}\sim \text{Beta}(\beta_0,\beta_1).
\]</div>
<p>与似然函数相乘后，得到后验，</p>
<div class="math notranslate nohighlight" id="equation-posterior-bayes">
<span class="eqno">(12)<a class="headerlink" href="#equation-posterior-bayes" title="Link to this equation">¶</a></span>\[
p(\pmb{\theta})=p(\pmb{\pi}|\mathcal{D})\prod_{j=1}^D\prod_{c=1}^C p(\theta_{jc}|\mathcal{D})
\]</div>
<p>由共轭先验可知后验形式，</p>
<div class="math notranslate nohighlight" id="equation-posterior-bayes-detail">
<span class="eqno">(13)<a class="headerlink" href="#equation-posterior-bayes-detail" title="Link to this equation">¶</a></span>\[
p(\pmb{\pi}|\mathcal{D})=\text{Dir}(N_1+\alpha_1,...,N_c+\alpha_c),\quad p(\theta_{jc}|\mathcal{D})=\text{Beta}((N_c-N_{jc})+\beta_0,N_{jc}+\beta_1)
\]</div>
<p>  （三）<strong>预测</strong></p>
<p>  预测的目标是计算后验，</p>
<div class="math notranslate nohighlight">
\[
p(y=c|\pmb{x},\mathcal{D})\propto p(y=c)\prod_{j=1}^D p(x_j|y=c,\mathcal{D})
\]</div>
<p>贝叶斯的作法是把未知参数积分去除，即，</p>
<div class="math notranslate nohighlight" id="equation-predict-bayes">
<span class="eqno">(14)<a class="headerlink" href="#equation-predict-bayes" title="Link to this equation">¶</a></span>\[\begin{split}
\begin{split}
p(y=c|\pmb{x},\mathcal{D})&amp;=\int \text{Cat}(y=c|\pmb{\pi})p(\pmb{\pi}|\mathcal{D})d\pi\\
&amp;\times \prod_{j=1}^D\int \text{Ber}(x_j|y=c,\theta_{jc})p(\theta_{jc}|\mathcal{D})d\theta_{jc}\\
&amp;=\bar{\pi}\prod_{j=1}^D\bar{\theta}_{jc}^{\mathbb{I}(x_j=1)}(1-\bar{\theta}_{jc})^{\mathbb{I}(x_j=0)}
\end{split}
\end{split}\]</div>
<p>其中，</p>
<div class="math notranslate nohighlight">
\[
\bar{\theta}_{jc}=\frac{N_{jc}+\beta_1}{N_c+\beta_0+\beta_1},\quad \bar{\pi}=\frac{N_c+\alpha_c}{N+\alpha_0}.\quad \alpha_0=\sum_c \alpha_c.
\]</div>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../index.html">目录</a></h3>
    <ul>
<li><a class="reference internal" href="#">5. 贝叶斯分类</a><ul>
<li><a class="reference internal" href="#id2">5.1. 贝叶斯决策</a></li>
<li><a class="reference internal" href="#id3">5.2. 朴素贝叶斯分类器</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>上一主题</h4>
    <p class="topless"><a href="PGM.html"
                          title="上一章"><span class="section-number">4. </span>概率图模型</a></p>
  </div>
  <div>
    <h4>下一主题</h4>
    <p class="topless"><a href="neuro_network.html"
                          title="下一章"><span class="section-number">6. </span>神经网络</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/ml/bayes.md.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">快速搜索</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="提交" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="Related">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="总索引"
             >索引</a></li>
        <li class="right" >
          <a href="neuro_network.html" title="6. 神经网络"
             >下一页</a> |</li>
        <li class="right" >
          <a href="PGM.html" title="4. 概率图模型"
             >上一页</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Machine Learning Fundation 1.0 文档</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">5. </span>贝叶斯分类</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; 版权所有 2022-2024, SSPUIIP.
      由 <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3创建。
    </div>
  </body>
</html>