<!doctype html>
<html class="no-js" lang="zh-CN" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="索引" href="../genindex.html" /><link rel="search" title="搜索" href="../search.html" /><link rel="next" title="7. 表示学习" href="neuro_representation.html" /><link rel="prev" title="5. 概率图模型" href="PGM.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2025.07.19 -->
        <title>6. 集成学习 - Machine Learning Fundation 1.0 文档</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Machine Learning Fundation 1.0 文档</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <span class="sidebar-brand-text">Machine Learning Fundation 1.0 文档</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="搜索" name="q" aria-label="搜索">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">基础知识</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../base/prob_dist.html">1. 概率及分布</a></li>
<li class="toctree-l1"><a class="reference internal" href="../base/gaussian_model.html">2. 高斯模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../base/gaussian_process.html">3. 高斯过程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../base/calc_theory.html">4. 计算学习理论</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">监督学习</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dimension_reduce_2.html">1. 数据降维</a></li>
<li class="toctree-l1"><a class="reference internal" href="decision_tree.html">2. 决策树</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayes.html">3. 贝叶斯分类</a></li>
<li class="toctree-l1"><a class="reference internal" href="EM.html">4. EM算法概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="PGM.html">5. 概率图模型</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">6. 集成学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="neuro_representation.html">7. 表示学习</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">深度学习</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="neuro_network_mlp.html">1. 神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="neuro_network_cnn.html">2. 卷积神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="neuro_network_rnn.html">3. 循环神经网络</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">无监督学习</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cmeans.html">1. 聚类(一)</a></li>
<li class="toctree-l1"><a class="reference internal" href="biClustering.html">2. BiClustering</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">核方法</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../kernel/base.html">1. 核函数基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kernel/base2.html">2. 核函数基础2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kernel/RKHS.html">3. 再生核希尔伯特空间</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kernel/MMD.html">4. 最大均值差</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kernel/covariance_operators.html">5. 协方差算子</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">最优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../optimization/convex_prob.html">1. 凸优化问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/convex_solve.html">2. 优化问题求解(1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/convex_neq_solve.html">3. 优化问题求解(2)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">矩阵分析</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../matrix/base.html">1. 矩阵性能指标</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matrix/matrixoper.html">2. 矩阵运算</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matrix/vectorspace.html">3. 向量空间</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matrix/matrixdiff.html">4. 矩阵微分</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matrix/special_matrix.html">5. 特殊矩阵</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matrix/subspace.html">6. 子空间分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matrix/decomposition.html">7. 矩阵分解</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">粗糙集</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../roughset/roughbase.html">1. 粗糙集基础</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">数学建模</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mathmodel/statistic_model.html">1. 不确定模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathmodel/bregman_divergence.html">2. Bregman divergence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathmodel/entropy.html">3. 信息熵</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathmodel/conjugate_dist.html">4. 共轭分布</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathmodel/mcmc.html">5. 随机模拟</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathmodel/RFF.html">6. Random Fourier features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathmodel/gumbel_trick.html">7. Gumbel Trick</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/ml/ensemble.md.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1><span class="section-number">6. </span>集成学习<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h1>
<p>  <strong>集成学习</strong>其实就是学习器集成，即通过构建多个学习器完成学习任务，综合所有学习器的学习结果按特定策略生成集成学习器的学习结果。结合策略一般有：平均法、投票法以及学习法等。</p>
<figure class="align-center" id="id6">
<pre  class="mermaid">
        %%{
    init: {
        'theme':'base',
        'themeVariables': {
            'fontSize': 8px
        }
    }
}%%
graph LR
A[集成学习] --&gt;B[不同类预测器同一训练集];
A[集成学习] -- 并行集成 --&gt;C[同类预测器采样训练子集];
B--&gt;D[硬投票法];
B--&gt;E[软投票法];
C--子集样本放回--&gt;F[Bagging];
C--子集样本不放回--&gt;G[Pasting];
A-- 串行集成 --&gt;H[训练模型集成];
H--&gt;I[Boosting];
H--&gt;J[Stacking];
I--调整样本权重与预测器权重--&gt;K[Adaboost];
I--对前一预测器的结果残差训练--&gt;L[GradientBoosting];
    </pre><figcaption>
<p><span class="caption-text">Fig 1. 集成学习概要</span><a class="headerlink" href="#id6" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><strong>为什么需要集成学习</strong>？</p></li>
</ul>
<p>  （1）<strong>通俗一点的解释：和”三个臭皮匠抵个诸葛亮“是一个道理</strong>。<br>  （2）<strong>从理论的角度：集成学习方法可以把弱学习器变成可以精确预测的强学习器</strong>。在PAC(Probabily approximately correct)学习框架中，如果存在一个多项式的学习算法可以学习一个类（概念），并且正确率很高，那么这个类（概念）是<strong>强可学习</strong>的。如果存在一个多项式的学习算法可以学习一个类（概念），学习效果（正确率）仅比随机猜测略好，那么这个概念是<strong>弱可学习</strong>的。已有研究证明：<strong>强可学习与弱可学习是等价的</strong>。也就是说，在PAC学习框架下，一个概念强可学习的充要条件是这个概念是弱可学习的。那么，已经发现的“弱可学习算法”，如何提升为“强可学习算法”？答案是集成学习。</p>
<section id="id2">
<h2><span class="section-number">6.1. </span>投票法<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h2>
<p>  要创建一个更好的分类器，是简单的办法就是聚合每个分类器的预测，然后将得票最多的结果作为预测类别，这种大多数投票分类器被称为<strong>硬投票分类器</strong>。如下图所示：</p>
<figure class="align-center" id="id7">
<pre  class="mermaid">
        %%{
    init: {
        'theme':'base',
        'themeVariables': {
            'fontSize': 8px
        }
    }
}%%
graph LR
	A((数据集)) --train--&gt; B[逻辑回归];
	A --train--&gt; C[SVM];
	A --train--&gt; D[随机森林];
	A --train--&gt; E[...];
	A --train--&gt; F[其它分类器];
	B -.predict.-&gt; G[+1/-1];
	C -.predict.-&gt; H[+1/-1];
	D -.predict.-&gt; I[+1/-1];
	E -.predict.-&gt; J[+1/-1];
	F -.predict.-&gt; K[+1/-1];
	G --vote--&gt; L[+1/-1];
	H --vote--&gt; L[+1/-1];
	I --vote--&gt; L[+1/-1];
	J --vote--&gt; L[+1/-1];
	K --vote--&gt; L[+1/-1];
    </pre><figcaption>
<p><span class="caption-text">Fig 2. 多学习器集成–投票法</span><a class="headerlink" href="#id7" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><strong>投票法效果</strong></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_moons</span>
<span class="c1">#数据集</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">VotingClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVC</span>

<span class="n">log_clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rnd_clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">svm_clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#硬投票法集成</span>
<span class="n">voting_clf</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">log_clf</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">rnd_clf</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;svc&#39;</span><span class="p">,</span> <span class="n">svm_clf</span><span class="p">)],</span>
    <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;hard&#39;</span><span class="p">)</span>
<span class="n">voting_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="p">(</span><span class="n">log_clf</span><span class="p">,</span> <span class="n">rnd_clf</span><span class="p">,</span> <span class="n">svm_clf</span><span class="p">,</span> <span class="n">voting_clf</span><span class="p">):</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>LogisticRegression 0.864
RandomForestClassifier 0.872
SVC 0.888
VotingClassifier 0.896
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">log_clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rnd_clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">svm_clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#软投票法</span>
<span class="n">voting_clf</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">log_clf</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">rnd_clf</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;svc&#39;</span><span class="p">,</span> <span class="n">svm_clf</span><span class="p">)],</span>
    <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span><span class="p">)</span>
<span class="n">voting_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="p">(</span><span class="n">log_clf</span><span class="p">,</span> <span class="n">rnd_clf</span><span class="p">,</span> <span class="n">svm_clf</span><span class="p">,</span> <span class="n">voting_clf</span><span class="p">):</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>LogisticRegression 0.864
RandomForestClassifier 0.872
SVC 0.888
VotingClassifier 0.912
</pre></div>
</div>
<p>  投票分类器的准确率通常比集成中最好的分类器还要高。事实上，即使每个分类器都是弱学习器，通过集成依然可以实现一个强学习器。只要有足够大数量且多种类的弱学习器即可。</p>
<ul class="simple">
<li><p><strong>为什么会有效？</strong></p></li>
</ul>
<p>  下面的类比可以帮助理解。假设一个略微偏倚的硬币，它有51％的机率正面向上。如果投1000次，大致会得到510次正面，所以正面是大多数。也就是说，在1000次投掷之后，大多数硬币正面向上（1000硬币参与结果投票，至少501个硬币结果为正面）的概率接近75％。即</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
1-\textrm{pbinom}(499,1000,0.51)\approx 74.67\%
\]</div>
</div>
<p>10000次后，这个概率达到97%。同理，假设有1000个分类器的集成，每个分类器都只有51%的概率是正确的。如果，以大多数投票的类别作为预测结果，可以达到准确率接近75%。</p>
</section>
<section id="baggingpasting">
<h2><span class="section-number">6.2. </span>并行集成：bagging和pasting<a class="headerlink" href="#baggingpasting" title="Link to this heading">¶</a></h2>
<p>  每个预测器使用相同算法，但在训练集的随机子集上进行训练。如果样本放回，这种方法称为bagging(bootstrap aggregating)；如果样本不放回，这种方法称为pasting。</p>
<figure class="align-center" id="id8">
<pre  class="mermaid">
        %%{
    init: {
        'theme':'base',
        'themeVariables': {
            'fontSize': 8px
        }
    }
}%%
graph LR
	A[(训练集)]  --随机选择--&gt; B[(子集1)]
	A[(训练集)]  --随机选择--&gt; C[(子集2)]
	A[(训练集)]  --随机选择--&gt; D[(子集3)]
	A[(训练集)]  --随机选择--&gt; E[(...)]
	A[(训练集)]  --随机选择--&gt; F[(子集k)]
	B --训练--&gt; G[分类器1]
	C --训练--&gt; H[分类器2]
	D --训练--&gt; I[分类器3]
	E --训练--&gt; J[...]
	 F --训练--&gt; K[分类器k]
	 G --测试集预测--&gt; L[+1/-1]
	 H --测试集预测--&gt;M[+1/-1]
	 I --测试集预测--&gt; N[+1/-1]
	J --测试集预测--&gt; O[+1/-1]
	K --测试集预测--&gt; P[+1/-1]
	L --集成--&gt; Q[+1/-1]
	O--集成--&gt; Q[+1/-1]
	M--集成--&gt; Q[+1/-1]
	N --集成--&gt; Q[+1/-1]
	P --集成--&gt; Q[+1/-1]
    </pre><figcaption>
<p><span class="caption-text">Fig 3. 并行集成示例</span><a class="headerlink" href="#id8" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><strong>并行集成的效果示例</strong></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#准备数据集</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_moons</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#Bagging集成分类器</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="n">bag_clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
    <span class="n">DecisionTreeClassifier</span><span class="p">(),</span> <span class="c1">#分类器种类</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>   <span class="c1">#分类器个数</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>    <span class="c1">#训练子集样本数</span>
    <span class="n">bootstrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>     <span class="c1">#bagging=True; pasting=False</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">bag_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1">#打印结果</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="nb">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1">#对比决策树</span>
<span class="n">tree_clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_tree</span> <span class="o">=</span> <span class="n">tree_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_tree</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>0.904
0.856
</pre></div>
</div>
</section>
<section id="id3">
<h2><span class="section-number">6.3. </span>串行集成：提升法<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h2>
<p>  提升法是指可以将几个弱学习器结合成一个强学习器的任意集成方法。大多数提升法的<strong>总体思路</strong>是循环训练预测器，每次都其前序做出一些改正。</p>
<figure class="align-center" id="id9">
<pre  class="mermaid">
        %%{
    init: {
        'theme':'base',
        'themeVariables': {
            'fontSize': 8px
        }
    }
}%%
flowchart  LR
  A2 o--o C1;
  A3 o--o C2;
  A4 o--o C3;  
  subgraph  次序训练1 
  A1[数据集0]--训练--&gt;B1[预测器];
  B1 --调整数据权重--&gt; C1[数据集1];
  end
  subgraph 次序训练2
  A2[数据集1]--训练--&gt;B2[预测器];
  B2--调整数据权重--&gt; C2[数据集2];
  end
  subgraph 次序训练...
  A3[...]-..- C3[...];
  end
  subgraph 次序训练n
  A4[数据集n-1]--训练--&gt;B4[预测器n];
  end
    </pre><figcaption>
<p><span class="caption-text">Fig 4. 提升法示意</span><a class="headerlink" href="#id9" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<section id="adaboost">
<h3><span class="section-number">6.3.1. </span>Adaboost<a class="headerlink" href="#adaboost" title="Link to this heading">¶</a></h3>
<p>  假设二分类情况，以下给出了Adaboost算法的框架。给定训练集<span class="math notranslate nohighlight">\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)</span>，其中<span class="math notranslate nohighlight">\(x_i\in\mathcal{X}\subseteq \mathbb{R}^n, y_i\in\mathcal{Y}=\{+1,-1\}\)</span>。</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>算法：Adaboost<span class="math notranslate nohighlight">\(\left(S=\{(\pmb{x}_1,y_1),(\pmb{x}_2,y_2),...,(\pmb{x}_m,y_m)\}\right)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>01 <strong>for</strong> <span class="math notranslate nohighlight">\(i=1\)</span> <strong>to</strong> <span class="math notranslate nohighlight">\(m\)</span><br>02   <span class="math notranslate nohighlight">\(w_1(i)=\frac1m\)</span><br>03 <strong>for</strong> <span class="math notranslate nohighlight">\(t=1\)</span> <strong>to</strong> <span class="math notranslate nohighlight">\(T\)</span><br>04   <span class="math notranslate nohighlight">\(f_t\leftarrow\)</span>误差<span class="math notranslate nohighlight">\(\epsilon_t=\mathop{\mathbb{P}}\limits_{\pmb{x}_i\sim w_t}\left[f_t(\pmb{x}_i)\neq y_i\right]\)</span>较小的基分类器<br>05   <span class="math notranslate nohighlight">\(\alpha_t\leftarrow \frac12\log\frac{1-\epsilon_t}{\epsilon_t}\)</span><br>06   <span class="math notranslate nohighlight">\(Z_t\leftarrow 2[\epsilon_t(1-\epsilon_t)]^{\frac12}\)</span> (归一化因子)<br>07   <strong>for</strong> <span class="math notranslate nohighlight">\(i=1\)</span> <strong>to</strong> <span class="math notranslate nohighlight">\(m\)</span><br>08     <span class="math notranslate nohighlight">\(w_{t+1}(i)\leftarrow\frac{w_t(i)\exp(-\alpha_t\times y_i\times f_t(\pmb{x}_i))}{Z_t}\)</span><br>09 <span class="math notranslate nohighlight">\(f\leftarrow \sum_{t=1}^T\alpha_t f_t\)</span><br>10 <strong>return</strong> <span class="math notranslate nohighlight">\(f\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<ul class="simple">
<li><p>初使化训练数据的权值分布</p></li>
</ul>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
W_1=(w^{(1)},...,w^{(N)}), w_{1i}=\frac{1}{N},i=1,2,...,N
\]</div>
</div>
<p>使用该权值分布对第一个预测器进行训练,</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
f_j(x):\mathcal{X}\rightarrow \{+1,-1\}, j=1,2,...,M
\]</div>
</div>
<p>计算加权误差率<span class="math notranslate nohighlight">\(r_1\)</span>如下，</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
r_j=\frac{\sum_{i=1,y_j^{(i)}\neq y^{(i)}}^N w^{(i)} }{\sum_{i=1}^N w^{(i)} }, j=1,2,...,M
\]</div>
</div>
<p>计算预测器权重<span class="math notranslate nohighlight">\(a_j\)</span>如下，</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
\alpha_j=\eta\log\frac{1-r_j}{r_j}, j=1,2,...,M
\]</div>
</div>
<ul class="simple">
<li><p>更新权值</p></li>
</ul>
<p>  对于<span class="math notranslate nohighlight">\(i=1,2,...,N\)</span>，如果<span class="math notranslate nohighlight">\(y_j^{(i)}=y^{(i)}\)</span>，则<span class="math notranslate nohighlight">\(w^{(i)}\leftarrow w^{(i)}\)</span>；否则，</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
w^{(i)}\leftarrow w^{(i)}\exp(\alpha_j)
\]</div>
</div>
<p>最后归一化，即，</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
w^{(i)}=\frac{w^{(i)}}{\sum_{i=1}^N w^{(i)}}
\]</div>
</div>
<ul class="simple">
<li><p>以此规则，训练后序所有预测器。</p></li>
</ul>
<p>  <strong>定理</strong>. AdaBoost返回的分类器经验误差满足，</p>
<div class="math-wrapper docutils container" id="equation-adaboost-bounder-1">
<div class="math notranslate nohighlight" id="equation-adaboost-bounder-1">
<span class="eqno">(1)<a class="headerlink" href="#equation-adaboost-bounder-1" title="Link to this equation">¶</a></span>\[
\boxed{
\hat{R}_S(f)\le\exp\left[-2\sum_{t=1}^T\left(\frac12-\epsilon_t\right)^2 \right]}
\]</div>
</div>
<p>如果对于所有<span class="math notranslate nohighlight">\(t\in [1,T]\)</span>，有<span class="math notranslate nohighlight">\(\gamma \le(\frac12-\epsilon_t)\)</span>成立，则有，</p>
<div class="math-wrapper docutils container" id="equation-adaboost-bounder-2">
<div class="math notranslate nohighlight" id="equation-adaboost-bounder-2">
<span class="eqno">(2)<a class="headerlink" href="#equation-adaboost-bounder-2" title="Link to this equation">¶</a></span>\[
\hat{R}_S(f)\le\exp\left[-2\gamma^2T\right]
\]</div>
</div>
<p>  <strong>证明</strong>. 根据一般不等式<span class="math notranslate nohighlight">\(1_{x\le 0}\le\exp(-x)\)</span>对于所有<span class="math notranslate nohighlight">\(x\in R\)</span>成立，则可以得到，</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\hat{R}_S(f)&amp;=\frac1m\sum_{i=1}^m 1_{y_if(x_i)\le 0}\\
&amp;\le\frac1m\sum_{i=1}^m e^{-y_if(x_i)}\\
&amp;=\frac1m\sum_{i=1}^m\left[m\prod_{t=1}^T Z_t \right]D_{T+1}(i)\\
&amp;=\prod_{t=1}^T Z_t
\end{split}
\end{split}\]</div>
</div>
<p>  <span class="math notranslate nohighlight">\(Z_t\)</span>是一个归一化因子，可以改写成如下形式，</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
Z_t &amp;= \sum_{i=1}^m D_t(i)e^{-a_ty_ih_t(x_i)}\\
&amp;=\sum_{i:y_ih_t(x_i)=+1}D_t(i)e^{-a_t}+\sum_{i:y_ih_t(x_i)=-1}D_t(i)e^{a_t}\\
&amp;=(1-\epsilon_t)e^{-a_t}+\epsilon_t e^{a_t}\\
&amp;=(1-\epsilon_t)\sqrt{\frac{\epsilon_t}{1-\epsilon_t}}+\epsilon_t\sqrt{\frac{1-\epsilon_t}{\epsilon_t}}\\
&amp;=2\sqrt{\epsilon_t(1-\epsilon_t)}
\end{split}
\end{split}\]</div>
</div>
<p>在上式的推导过程中，注意有：<span class="math notranslate nohighlight">\(\epsilon_t=\mathop{\mathbb{P}}\limits_{x_i\sim D_t}\left[h_t(x_i)\neq y_i \right]\)</span>以及<span class="math notranslate nohighlight">\(a_t=\frac12\log\frac{1-\epsilon_t}{\epsilon_t}\)</span>成立。</p>
<p>  因此，归一化因子的乘积上界可以表示为，</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\prod_{i=1}^T Z_t&amp;=\prod_{t=1}^T2\sqrt{\epsilon_t(1-\epsilon_t)}\\
&amp;=\prod_{i=1}^T\sqrt{1-4\left(\frac12-\epsilon_t \right)^2}\\
&amp;\le\prod\exp\left[-2\left(\frac12-\epsilon_t\right)^2\right]\\
&amp;=\exp\left[-2\sum_{i=1}^T\left(\frac12-\epsilon_t\right)^2 \right]
\end{split}
\end{split}\]</div>
</div>
<section id="id4">
<h4><span class="section-number">6.3.1.1. </span>AdaBoost分类器预测<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h4>
<p>  集成分类器训练好之后，就可以按以下规则预测，</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
\hat{y}(x)=\arg\max_{k} \sum_{j=1,\hat{y}_j(x)=k}^M \alpha_j
\]</div>
</div>
</section>
<section id="id5">
<h4><span class="section-number">6.3.1.2. </span>AdaBoost例子<a class="headerlink" href="#id5" title="Link to this heading">¶</a></h4>
<p>  给定以下训练数据。假设弱分类器由<span class="math notranslate nohighlight">\(x&lt;v\)</span>或<span class="math notranslate nohighlight">\(x&gt;v\)</span>产生，其阈值<span class="math notranslate nohighlight">\(v\)</span>使该分类器在训练数据集上分类误差率最低。下面用AdaBoost算法学习一个强分类器。</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>序号</p></th>
<th class="head"><p>1</p></th>
<th class="head"><p>2</p></th>
<th class="head"><p>3</p></th>
<th class="head"><p>4</p></th>
<th class="head"><p>5</p></th>
<th class="head"><p>6</p></th>
<th class="head"><p>7</p></th>
<th class="head"><p>8</p></th>
<th class="head"><p>9</p></th>
<th class="head"><p>10</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(x\)</span></p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
<td><p>8</p></td>
<td><p>9</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(y\)</span></p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>-1</p></td>
<td><p>-1</p></td>
<td><p>-1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>-1</p></td>
</tr>
</tbody>
</table>
</div>
<div align="center">表1：训练数据</div>
<p>  第一步，先求数据集的初使权值分布，</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
w^{(i)}=\frac{1}{10}, i=1,2,...,10
\]</div>
</div>
<p>在这个权值分布训练数据上，阈值取3.5时，分类误差率最低，故基本分类器为<span class="math notranslate nohighlight">\(f_1(x)=1; x&lt;3.5\)</span>。<span class="math notranslate nohighlight">\(f_1(x)\)</span>在训练集的误差<span class="math notranslate nohighlight">\(r_1\)</span>为<span class="math notranslate nohighlight">\(0.3\)</span>。所以，分类器<span class="math notranslate nohighlight">\(f_1(x)\)</span>的权值为：<span class="math notranslate nohighlight">\(a_1=\eta\log\frac{1-r_1}{r_1}=0.4236\)</span>，这里<span class="math notranslate nohighlight">\(\eta=0.5\)</span>。</p>
<p>  第二步，更新权值分布，</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
w^{(i)}&amp;=0.1;\quad i=1,2,...,6,10.\\
w^{(i)}&amp;=0.1\exp(a_1)=0.1527;\quad i=7,8,9.
\end{split}
\end{split}\]</div>
</div>
<p>  归一化后得，</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>序号</p></th>
<th class="head"><p>1</p></th>
<th class="head"><p>2</p></th>
<th class="head"><p>3</p></th>
<th class="head"><p>4</p></th>
<th class="head"><p>5</p></th>
<th class="head"><p>6</p></th>
<th class="head"><p>7</p></th>
<th class="head"><p>8</p></th>
<th class="head"><p>9</p></th>
<th class="head"><p>10</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(w\)</span></p></td>
<td><p>0.08633</p></td>
<td><p>0.08633</p></td>
<td><p>0.08633</p></td>
<td><p>0.08633</p></td>
<td><p>0.08633</p></td>
<td><p>0.08633</p></td>
<td><p>0.13188</p></td>
<td><p>0.13188</p></td>
<td><p>0.13188</p></td>
<td><p>0.08633</p></td>
</tr>
</tbody>
</table>
</div>
<p>分类器<span class="math notranslate nohighlight">\(f_1(x)\)</span>的权值<span class="math notranslate nohighlight">\(u^{(1)}\)</span>为：<span class="math notranslate nohighlight">\(0.4236\)</span></p>
<p>  第三步，以第一步和第二步的规则执行，直到所有分类器都已训练。</p>
<p>  最终分类器为</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
f(x)=\textrm{sign}(u^{(1)}f_1(x)+u^{(2)}f_2(x)+...+u^{(k)}f_k(x))
\]</div>
</div>
</section>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="neuro_representation.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title"><span class="section-number">7. </span>表示学习</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="PGM.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title"><span class="section-number">5. </span>概率图模型</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022-2024, SSPUIIP
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">6. 集成学习</a><ul>
<li><a class="reference internal" href="#id2">6.1. 投票法</a></li>
<li><a class="reference internal" href="#baggingpasting">6.2. 并行集成：bagging和pasting</a></li>
<li><a class="reference internal" href="#id3">6.3. 串行集成：提升法</a><ul>
<li><a class="reference internal" href="#adaboost">6.3.1. Adaboost</a><ul>
<li><a class="reference internal" href="#id4">6.3.1.1. AdaBoost分类器预测</a></li>
<li><a class="reference internal" href="#id5">6.3.1.2. AdaBoost例子</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=f115507d"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="../_static/mathjax/tex-chtml.js"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">
import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.esm.min.mjs";
window.addEventListener("load", () => mermaid.run());
</script>
    </body>
</html>