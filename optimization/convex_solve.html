
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>2. 优化问题求解 &#8212; MLBOOK 1.0 文档</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../_static/translations.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="../_static/mathjax/tex-chtml.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="prev" title="1. 凸优化问题" href="convex_prob.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="zh_CN">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">MLBOOK 1.0 文档</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  矩阵分析
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../matrix/base.html">
   1. 矩阵性能指标
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../matrix/matrixoper.html">
   2. 矩阵运算
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../matrix/vectorspace.html">
   3. 向量空间
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../matrix/matrixdiff.html">
   4. 矩阵微分
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  最优化
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="convex_prob.html">
   1. 凸优化问题
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   2. 优化问题求解
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/optimization/convex_solve.md.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   2.1. 下降法
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     2.1.1. 最速下降法
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#newton">
     2.1.2. Newton法
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   2.2. 梯度投影法
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   2.3. 共轭梯度下降法
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mathbf-a">
     2.3.1.
     <span class="math notranslate nohighlight">
      \(\mathbf{A}\)
     </span>
     -共轭
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     2.3.2. 共轭梯度法
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     2.3.3. 案例
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>优化问题求解</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   2.1. 下降法
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     2.1.1. 最速下降法
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#newton">
     2.1.2. Newton法
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   2.2. 梯度投影法
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   2.3. 共轭梯度下降法
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mathbf-a">
     2.3.1.
     <span class="math notranslate nohighlight">
      \(\mathbf{A}\)
     </span>
     -共轭
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     2.3.2. 共轭梯度法
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     2.3.3. 案例
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="id1">
<h1><span class="section-number">2. </span>优化问题求解<a class="headerlink" href="#id1" title="永久链接至标题">#</a></h1>
<section id="id2">
<h2><span class="section-number">2.1. </span>下降法<a class="headerlink" href="#id2" title="永久链接至标题">#</a></h2>
<p>基本思想：利用优化序列</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_{k+1}=\mathbf{x}_k+\mu_k\Delta\mathbf{x}_k,\quad k=1,2,\cdots\tag{1}
\]</div>
<p>寻找最优点<span class="math notranslate nohighlight">\(\mathbf{x}_{opt}\)</span>。<span class="math notranslate nohighlight">\(\mu_k\)</span>为第<span class="math notranslate nohighlight">\(k\)</span>次迭代的步长，<span class="math notranslate nohighlight">\(\Delta\mathbf{x}_k\)</span>为搜索方向其值为一个向量<span class="math notranslate nohighlight">\(\Delta\mathbf{x}\in\mathbb{R}^n\)</span>。最小化算法要求迭代过程中目标函数是下降的，</p>
<div class="math notranslate nohighlight">
\[
f(\mathbf{x}_{k+1})&lt;f(\mathbf{x}_k)
\]</div>
<p>所以该方法称为<font color='red'><strong>下降法</strong></font>。</p>
<section id="id3">
<h3><span class="section-number">2.1.1. </span>最速下降法<a class="headerlink" href="#id3" title="永久链接至标题">#</a></h3>
<p>由Taylor公式可知，</p>
<div class="math notranslate nohighlight">
\[
f(\mathbf{x}_{k+1})- f(\mathbf{x}_k)\approx\nabla f(\mathbf{x}_k)^\top\Delta\mathbf{x}_k\tag{2}
\]</div>
<p>显然，当<span class="math notranslate nohighlight">\(0\le\theta\le \pi/2\)</span>, 令</p>
<div class="math notranslate nohighlight">
\[
\Delta\mathbf{x}_k=-\nabla f(\mathbf{x}_k)\cos\theta\tag{3}
\]</div>
<p>必然有，<span class="math notranslate nohighlight">\(f(\mathbf{x}_{k+1})&lt;f(\mathbf{x}_k)\)</span>成立。</p>
<ul class="simple">
<li><p>取<span class="math notranslate nohighlight">\(\theta=0\)</span>，则<span class="math notranslate nohighlight">\(\Delta\mathbf{x}_k=-\nabla f(\mathbf{x}_k)\)</span>，即搜索方向为负梯度方向，步长为<span class="math notranslate nohighlight">\(\lVert \nabla f(\mathbf{x}_k)\rVert_2^2\)</span>，故下降方向具有最大的下降步伐。与之对应的下降法称为<font color='red'><strong>最速下降法</strong></font>。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_{k+1}=\mathbf{x}_k+\mu_k\nabla f(\mathbf{x}_k)\tag{4}
\]</div>
</section>
<section id="newton">
<h3><span class="section-number">2.1.2. </span>Newton法<a class="headerlink" href="#newton" title="永久链接至标题">#</a></h3>
<p>Taylor公式展开至二阶有，</p>
<div class="math notranslate nohighlight">
\[
f(\mathbf{x}_{k+1})\approx f(\mathbf{x}_k)+\nabla f(\mathbf{x}_k)^\top\Delta\mathbf{x}_k+\frac12(\Delta\mathbf{x}_k)^\top\nabla^2f(\mathbf{x}_k)(\Delta\mathbf{x}_k)\tag{5}
\]</div>
<p>显然最优化下降方向应该是让二阶展开式最得最小值的方向，即</p>
<div class="math notranslate nohighlight">
\[
\min\limits_{\Delta\mathbf{x}_k}\left[f(\mathbf{x}_k)+\nabla f(\mathbf{x}_k)^\top\Delta\mathbf{x}_k+\frac12(\Delta\mathbf{x}_k)^\top\nabla^2f(\mathbf{x}_k)(\Delta\mathbf{x}_k)\right]\tag{6}
\]</div>
<p>对二阶展开式求导，可知，</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial f(\mathbf{x}_k+\Delta\mathbf{x}_k)}{\partial \Delta\mathbf{x}_k}=\nabla f(\mathbf{x}_k)+\nabla^2f(\mathbf{x}_k)\Delta\mathbf{x}_k=0\tag{7}
\]</div>
<p>则有最优搜索方向，</p>
<div class="math notranslate nohighlight">
\[
\Delta\mathbf{x}_k=-\nabla^2f(\mathbf{x}_k)\nabla f(\mathbf{x}_k)\tag{8}
\]</div>
<p>该下降方向也称之为Newton步或Newton下降方向，记为<span class="math notranslate nohighlight">\(\Delta\mathbf{x}_{nt}\)</span>，相应的方法称为<font color='red'><strong>Newton法</strong></font>。</p>
</section>
</section>
<section id="id4">
<h2><span class="section-number">2.2. </span>梯度投影法<a class="headerlink" href="#id4" title="永久链接至标题">#</a></h2>
<p>梯度下降法中变元是无约束的。若有约束<span class="math notranslate nohighlight">\(\mathbf{x}\in\mathcal{C}\)</span>，则梯度下降法中的更新公式应用投影代替，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_{k+1}=\mathcal{P}_\mathcal{C}(\mathbf{x}_k-\mu_k\nabla f(\mathbf{x}_k))\tag{9}
\]</div>
<p>这一算法称为梯度投影法，也称为投影梯度法。投影算子<span class="math notranslate nohighlight">\(\mathcal{P}_\mathcal{C}(\mathbf{y})\)</span>定义为</p>
<div class="math notranslate nohighlight">
\[
\mathcal{P}_\mathcal{C}(\mathbf{y})=\arg\min\limits_{\mathbf{x}\in\mathcal{C}}\frac12\lVert \mathbf{x}-\mathbf{y}\rVert_2^2\tag{10}
\]</div>
<p><strong>例</strong>. 到超平面<span class="math notranslate nohighlight">\(\mathcal{C}=\{\mathbf{x}|\mathbf{a}^\top\mathbf{x}=b\}\)</span>的投影，</p>
<div class="math notranslate nohighlight">
\[
\mathcal{P}_\mathcal{C}(\mathbf{x})=\mathbf{x}+\frac{b-\mathbf{a}^\top\mathbf{x}}{\lVert\mathbf{a}\rVert_2^2}\mathbf{a}
\]</div>
<p>求解过程：投影问题为如下优化问题，</p>
<div class="math notranslate nohighlight">
\[
\mathcal{P}_\mathcal{C}(\mathbf{x})=\arg\min\limits_{\mathbf{z}\in\mathcal{C}}\frac12\lVert \mathbf{x}-\mathbf{z}\rVert_2^2 \quad s.t.\quad \mathbf{a}^\top\mathbf{x}-b=0
\]</div>
<p>则Lagrangian函数为，</p>
<div class="math notranslate nohighlight">
\[
L(\mathbf{x},\lambda)=\frac12\lVert \mathbf{x}-\mathbf{z}\rVert_2^2  +\lambda( \mathbf{a}^\top\mathbf{z}-b)
\]</div>
<p>对Lagrangian函数求偏导并令其等于0，可得</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\frac{\partial L}{\partial \mathbf{z}}&amp;=\mathbf{z}-\mathbf{x}+\lambda \mathbf{a}=0\\
\frac{\partial L}{\partial \lambda}&amp;=\mathbf{a}^\top\mathbf{z}-b=0\\
\end{split}
\end{split}\]</div>
<p>解上述方程组，将<span class="math notranslate nohighlight">\(\mathbf{z}=\mathbf{x}-\lambda \mathbf{a}\)</span>代入<span class="math notranslate nohighlight">\(\mathbf{a}^\top\mathbf{z}-b=0\)</span>，可得，</p>
<div class="math notranslate nohighlight">
\[
\lambda = \frac{\mathbf{a}^\top\mathbf{x}-b}{\mathbf{a}^\top\mathbf{a}}
\]</div>
<p>再将<span class="math notranslate nohighlight">\(\lambda\)</span>代入<span class="math notranslate nohighlight">\(\mathbf{z}-\mathbf{x}+\lambda \mathbf{a}=0\)</span>，可得</p>
<div class="math notranslate nohighlight">
\[
\mathbf{z}=\mathbf{x}+\frac{b-\mathbf{a}^\top\mathbf{x}}{\mathbf{a}^\top\mathbf{a}}\mathbf{a}
\]</div>
</section>
<section id="id5">
<h2><span class="section-number">2.3. </span>共轭梯度下降法<a class="headerlink" href="#id5" title="永久链接至标题">#</a></h2>
<p>最速下降法的存在一个问题就是收敛速度过慢，因为已迭代的<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>会来回振荡，从而导致收敛太慢。</p>
<p>Newton法虽然收收敛较快，但仍需要计算Hessian矩阵的逆，因此计算代价太高。</p>
<p>为了加速最速下降法的收敛速度和避免Newton法的Hessian逆矩阵计算，提出了共轭梯度下降法。</p>
<p><img alt="alt Conjugate Gradient Descent" src="../_images/conj_desc.png" /></p>
<p>与前面两种下降方法类似，共轭梯度下降也是通过迭代来寻找最优点，即</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_{k+1}=\mathbf{x}_k+\alpha_k\mathbf{d}_k\tag{11}
\]</div>
<p><strong>不同之处</strong>在于，每次迭代的下降方向向量<span class="math notranslate nohighlight">\(\mathbf{d}_i\)</span>与其它任何一次方向向量<span class="math notranslate nohighlight">\(\mathbf{d}_j,j\neq i\)</span>都是<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭的；此外，<span class="math notranslate nohighlight">\(\alpha_i\)</span>是<span class="math notranslate nohighlight">\(\min\limits_{\alpha}f(\mathbf{x}_{i-1}+\alpha\mathbf{d}_i)\)</span>的最优值。</p>
<p>为了简要描述共轭的思想，以上图为例，坐标轴可以指定为搜索方向。第一步沿着水平方向到达<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>的<span class="math notranslate nohighlight">\(x_1\)</span>分量部分。第二步没着垂直方向到达<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>的<span class="math notranslate nohighlight">\(x_2\)</span>分量部分，然后结束搜索过程就可以确定<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>的值。如果定义<span class="math notranslate nohighlight">\(\mathbf{e}_i=\mathbf{x}^*-\mathbf{x}_i\)</span>，则可以发现,</p>
<div class="math notranslate nohighlight">
\[
\mathbf{d}_i^\top\mathbf{e}_{i+1}=0
\]</div>
<p>共轭梯度下降法源于二次规划问题的求解，即</p>
<div class="math notranslate nohighlight">
\[
\min\limits_{\mathbf{x}}\quad \frac12\mathbf{x}^\top\mathbf{A}\mathbf{x}-\mathbf{b}^\top\mathbf{x}\quad(\mathbf{A}\succeq0)
\]</div>
<p>其梯度为<span class="math notranslate nohighlight">\(\nabla f(\mathbf{x})=\mathbf{Ax}-b\triangleq r(\mathbf{x})\)</span>，则求解最优值<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>等价于求解方程组<span class="math notranslate nohighlight">\(\mathbf{Ax}-\mathbf{b}=\mathbf{0}\)</span>。如果<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>是一个对称正定矩阵，那么必然可以构建一个<span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>空间的一个基，显然基的每个向量与其它基向量是共轭的。</p>
<p>下降方向能不能和这些基向量建立联系呢？答案是肯定的。易知，最优解<span class="math notranslate nohighlight">\(\mathbf{x}^\top\)</span>可以表示为</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^*=\sum_{i=0}^{n-1}\alpha_i\mathbf{d}_i\tag{12}
\]</div>
<p>如果<span class="math notranslate nohighlight">\(\alpha_i,\mathbf{d}_i\)</span>都已知，则<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>可通过上式确定。</p>
<section id="mathbf-a">
<h3><span class="section-number">2.3.1. </span><span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭<a class="headerlink" href="#mathbf-a" title="永久链接至标题">#</a></h3>
<p><strong>定义1</strong>.假设<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>是一个对称正定矩阵，那么称向量<span class="math notranslate nohighlight">\(\mathbf{d}_i,\mathbf{d}_j\)</span>是<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭的，如果满足，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{d}_i^\top\mathbf{A}\mathbf{d}_j=0,\quad i\neq j.
\]</div>
<p><strong>定理1</strong>. 两两向量相互<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭的向量集<span class="math notranslate nohighlight">\(\{\mathbf{d}_0,...,\mathbf{d}_{n-1}\}\)</span>构成了一个<span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>空间的一个基，即<span class="math notranslate nohighlight">\(\{\mathbf{d}_0,...,\mathbf{d}_{n-1}\}\)</span>线性无关。</p>
<p>有了<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭就可以来确定式(12)的各参数值了。</p>
<ul class="simple">
<li><p>首先求<span class="math notranslate nohighlight">\(\alpha_i\)</span>的表达式。</p></li>
</ul>
<p>对式(12)左右同时乘上<span class="math notranslate nohighlight">\(\mathbf{d}_k^\top\mathbf{A}\)</span>，利用<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭性可得</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{d}_k^\top\mathbf{A}\mathbf{x}^*&amp;=\sum_{i=0}^{n-1}\alpha_i\mathbf{d}_k^\top\mathbf{Ad}_i\\
\Rightarrow\alpha_k&amp;=\frac{\mathbf{d}_k^\top\mathbf{b}}{\mathbf{d}_k^\top\mathbf{Ad}_k}
\end{split}
\end{split}\]</div>
<p>可以看出，<span class="math notranslate nohighlight">\(\alpha_k\)</span>只与搜索方向<span class="math notranslate nohighlight">\(\mathbf{d}_k\)</span>有关，因此，只需要迭代<span class="math notranslate nohighlight">\(n\)</span>次就可以计算出<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>，即</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^*=\sum_{i=0}^{n-1}\frac{\mathbf{d}_i^\top\mathbf{b}}{\mathbf{d}_i^\top\mathbf{Ad}_i}\mathbf{d}_i
\]</div>
<p>为了演示上述过程在<span class="math notranslate nohighlight">\(n\)</span>步计算出<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>，引入如下定理。</p>
<p><strong>定理2</strong>. 假设<span class="math notranslate nohighlight">\(\{\mathbf{d}_0,...,\mathbf{d}_{n-1}\}\)</span>是<span class="math notranslate nohighlight">\(n\)</span>个<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭的向量，<span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>是初使点，令</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{x}_{k+1}&amp;=\mathbf{x}_k+\alpha_k\mathbf{d}_k\\
\mathbf{g}_k&amp;=\mathbf{b}-\mathbf{Ax}_k\\
\alpha_k&amp;=\frac{\mathbf{g}_k^\top\mathbf{d}_k}{\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_k}=\frac{(\mathbf{b}-\mathbf{Ax})_k^\top\mathbf{d}_k}{\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_k}
\end{split}
\end{split}\]</div>
<p>则迭代<span class="math notranslate nohighlight">\(n\)</span>次后，<span class="math notranslate nohighlight">\(\mathbf{x}_n=\mathbf{x}^*\)</span>。</p>
<p><strong>证明</strong>. 从起始点<span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>到<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>的误差<span class="math notranslate nohighlight">\(\mathbf{e}_0\)</span>为，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^*-\mathbf{x}_0=\alpha_0\mathbf{d}_0+\alpha_1\mathbf{d}_1+\cdots+\alpha_{n-1}\mathbf{d}_{n-1}
\]</div>
<p>从起始点<span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>到<span class="math notranslate nohighlight">\(\mathbf{x}_k\)</span>可以表示为，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_k-\mathbf{x}_0=\alpha_0\mathbf{d}_0+\alpha_1\mathbf{d}_1+\cdots+\alpha_{k-1}\mathbf{d}_{k-1}
\]</div>
<p><span class="math notranslate nohighlight">\(\mathbf{x}_k\)</span>的残差为</p>
<div class="math notranslate nohighlight">
\[
\mathbf{g}_k=\mathbf{b}-\mathbf{Ax}_k=\mathbf{A}(\mathbf{x}^*-\mathbf{x}_k)
\]</div>
<p>因此可得<span class="math notranslate nohighlight">\(\alpha_k\)</span>如下，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_0)&amp;=\mathbf{d}_k^\top\mathbf{A}( \alpha_0\mathbf{d}_0+\alpha_1\mathbf{d}_1+\cdots+\alpha_{n-1}\mathbf{d}_{n-1})=\alpha_k\mathbf{d}_k^\top\mathbf{Ad}_k\\
\Rightarrow\alpha_k&amp;=\frac{\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_0)}{\mathbf{d}_k^\top\mathbf{Ad}_k}
\end{split}
\end{split}\]</div>
<p>但仍然需要提前知道<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>才能计算<span class="math notranslate nohighlight">\(\alpha_k\)</span>。下面分析一下分子项。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_0)&amp;=\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_k+\mathbf{x}_k-\mathbf{x}_0)\\
&amp;=\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_k)
\end{split}
\end{split}\]</div>
<p>上式中，用到了<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭性，因此可以得知<span class="math notranslate nohighlight">\(\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}_k-\mathbf{x}_0)=0\)</span>。</p>
<p>最终有，</p>
<div class="math notranslate nohighlight">
\[
\alpha_k=\frac{\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_k)}{\mathbf{d}_k^\top\mathbf{Ad}_k}=\frac{\mathbf{d}_k^\top\mathbf{g}_k}{\mathbf{d}_k^\top\mathbf{Ad}_k}\tag{13}
\]</div>
</section>
<section id="id6">
<h3><span class="section-number">2.3.2. </span>共轭梯度法<a class="headerlink" href="#id6" title="永久链接至标题">#</a></h3>
<p>共轭梯度法是一种共轭方向方法。该方法选择的相继的方向向量被视为方法执行时相继获得的梯度的共轭版本。共轭方向并不是提前指定的，而是在每次序贯迭代时确定的。</p>
<p>假设有<span class="math notranslate nohighlight">\(D=\{\mathbf{d}_1,...,\mathbf{d}_n\}\)</span>是<span class="math notranslate nohighlight">\(n\)</span>个<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭向量集，则函数<span class="math notranslate nohighlight">\(f(\mathbf{x}_0+\alpha_1\mathbf{d}_1+\cdots+\alpha_n\mathbf{d}_n)\)</span>的最小化可以从<span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>出发沿着<span class="math notranslate nohighlight">\(\mathbf{d}_1\)</span>的方向到达极小值点<span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span>，然后从<span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span>出发沿着<span class="math notranslate nohighlight">\(\mathbf{d}_2\)</span>的方向到达极小值点<span class="math notranslate nohighlight">\(\mathbf{x}_2\)</span>，如此继续就可以达到函数的最小值点。这种优化方法称之为共轭梯度法。</p>
<p>上一节根据<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭已解决了<span class="math notranslate nohighlight">\(\alpha_i\)</span>的计算问题，剩下的工作就是要解决<span class="math notranslate nohighlight">\(\mathbf{d}_i\)</span>的计算问题。</p>
<p>线性共轭梯度法一般使用以下规则来确定共轭方向<span class="math notranslate nohighlight">\(\mathbf{d}_{k+1}\)</span>，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{d}_{k+1}=\mathbf{g}_k+\beta_k\mathbf{d}_{k}\tag{14}
\]</div>
<p>即，下一个搜索方向是上一个搜索方向与负梯度的线性组合。那么，<span class="math notranslate nohighlight">\(\beta_k\)</span>怎么确定呢？</p>
<p>显然，根据<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭性可知，<span class="math notranslate nohighlight">\(\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_{k+1}=0\)</span>，因此，对式(14)左右同时乘上<span class="math notranslate nohighlight">\(\mathbf{d}_k^\top\mathbf{A}\)</span>可得，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_{k+1}=\mathbf{d}_k^\top\mathbf{A}\mathbf{g}_{k}+\beta_k\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_{k}=0
\]</div>
<p>整理可得，</p>
<div class="math notranslate nohighlight">
\[
\beta_k=-\frac{\mathbf{d}_k^\top\mathbf{A}\mathbf{g}_{k}}{\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_{k}}\tag{15}
\]</div>
<p>至此，线性共轭梯度算法的所有参数<span class="math notranslate nohighlight">\((\alpha_i,\beta_i)\)</span>已确定。</p>
</section>
<section id="id7">
<h3><span class="section-number">2.3.3. </span>案例<a class="headerlink" href="#id7" title="永久链接至标题">#</a></h3>
<p><strong>例1</strong>. 考虑如下二次规划，</p>
<div class="math notranslate nohighlight">
\[
f(\mathbf{x})=\frac12\mathbf{x}^\top\mathbf{A}\mathbf{x}+\mathbf{b}^\top\mathbf{x}
\]</div>
<p>其中，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{A}=\left[\begin{array}{cc}\frac12&amp;\frac12\\\frac12&amp;1\end{array}\right],\quad\mathbf{b}=\left[\begin{array}{c}0\\2\end{array}\right]
\end{split}\]</div>
<p>求函数最小值，以及变量最优解<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span><span class="o">+</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">linear_conj_desc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">A</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">epsilon</span><span class="p">):</span>
    <span class="n">g</span><span class="o">=</span><span class="n">b</span><span class="o">-</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">g</span> <span class="c1"># negative descent direction</span>
    
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">g</span><span class="p">)</span><span class="o">&lt;=</span><span class="n">epsilon</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">alpha</span><span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">g</span><span class="p">)</span><span class="o">/</span><span class="n">d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">alpha</span><span class="o">*</span><span class="n">d</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">b</span><span class="o">-</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="o">-</span><span class="n">d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">g</span><span class="p">))</span><span class="o">/</span><span class="n">d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">g</span><span class="o">+</span><span class="n">beta</span><span class="o">*</span><span class="n">d</span>


<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">A</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">],[</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">b</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span><span class="mf">2.</span><span class="p">])</span>
    <span class="n">x_</span><span class="p">,</span><span class="n">f_</span><span class="o">=</span><span class="n">linear_conj_desc</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.3</span><span class="p">,</span><span class="o">-</span><span class="mf">2.2</span><span class="p">]),</span><span class="n">A</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="mi">10</span><span class="o">**-</span><span class="mi">5</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x=&quot;</span><span class="p">,</span><span class="n">x_</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">f_=&quot;</span><span class="p">,</span><span class="n">f_</span><span class="p">)</span>
</pre></div>
</div>
<p>最后输出为，</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">4.</span>  <span class="mf">4.</span><span class="p">]</span>
<span class="n">f_</span><span class="o">=</span> <span class="o">-</span><span class="mf">1.7763568394002505e-15</span>
</pre></div>
</div>
</section>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="convex_prob.html" title="上一页 页">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">上一页</p>
            <p class="prev-next-title"><span class="section-number">1. </span>凸优化问题</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By SSPUIIP<br/>
  
      &copy; Copyright 2022, SSPUIIP.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>