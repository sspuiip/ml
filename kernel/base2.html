<!DOCTYPE html>

<html lang="zh-CN" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2. 核函数基础2 &#8212; Machine Learning Fundation 1.0 文档</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css?v=279e0f84" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="../_static/documentation_options.js?v=f115507d"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="../_static/mathjax/tex-chtml.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="3. 再生核希尔伯特空间" href="RKHS.html" />
    <link rel="prev" title="1. 核函数基础" href="base.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="Related">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="总索引"
             accesskey="I">索引</a></li>
        <li class="right" >
          <a href="RKHS.html" title="3. 再生核希尔伯特空间"
             accesskey="N">下一页</a> |</li>
        <li class="right" >
          <a href="base.html" title="1. 核函数基础"
             accesskey="P">上一页</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Machine Learning Fundation 1.0 文档</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">2. </span>核函数基础2</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1><span class="section-number">2. </span>核函数基础2<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h1>
<section id="id2">
<h2><span class="section-number">2.1. </span>投影<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h2>
<p>  <strong>定义 （投影）</strong>. 投影<span class="math notranslate nohighlight">\(P\)</span>是一个映射，且满足以下条件：</p>
<div class="math notranslate nohighlight" id="equation-vector-proj">
<span class="eqno">(1)<a class="headerlink" href="#equation-vector-proj" title="Link to this equation">¶</a></span>\[
P(\pmb{x})=P(P(\pmb{x}))\quad\wedge\quad\langle P(\pmb{x}),\pmb{x}-P(\pmb{x})\rangle=0
\]</div>
<p>  <strong>定义 （正交投影）</strong>. 投影<span class="math notranslate nohighlight">\(P\)</span>的正交投影<span class="math notranslate nohighlight">\(P^\perp\)</span>为，</p>
<div class="math notranslate nohighlight" id="equation-orthogonal-proj">
<span class="eqno">(2)<a class="headerlink" href="#equation-orthogonal-proj" title="Link to this equation">¶</a></span>\[
P^\perp(\pmb{x}) \triangleq \pmb{x}-P(\pmb{x})
\]</div>
<p>  <span class="math notranslate nohighlight">\(\phi(\pmb{x})\)</span>在向量<span class="math notranslate nohighlight">\(\pmb{w}\)</span>上的<strong>投影</strong><span class="math notranslate nohighlight">\(P_{\pmb{w}}(\phi(\pmb{x}))\)</span>为，</p>
<div class="math notranslate nohighlight">
\[
P_{\pmb{w}}(\phi(\pmb{x}))=\frac{\langle\phi(\pmb{x}),\pmb{w}\rangle}{\Vert\pmb{w}\Vert}\cdot\frac{\pmb{w}}{\Vert\pmb{w}\Vert}=\frac{\langle\phi(\pmb{x}),\pmb{w}\rangle}{\Vert\pmb{w}\Vert^2}\cdot\pmb{w}
\]</div>
<p>如果<span class="math notranslate nohighlight">\(\pmb{w}\)</span>已单位化，则有，</p>
<div class="math notranslate nohighlight" id="equation-feature-proj">
<span class="eqno">(3)<a class="headerlink" href="#equation-feature-proj" title="Link to this equation">¶</a></span>\[
P_{\pmb{w}}(\phi(\pmb{x}))=\langle\phi(\pmb{x}),\pmb{w}\rangle\cdot\pmb{w}=\pmb{w}\cdot\langle\phi(\pmb{x}),\pmb{w}\rangle=\pmb{w}\pmb{w}^\top\phi(\pmb{x})
\]</div>
<p>因此，<strong>正交投影</strong><span class="math notranslate nohighlight">\( P_{\pmb{w}}^\bot \phi(\pmb{x}) \)</span> 为，</p>
<div class="math notranslate nohighlight" id="equation-feature-orthogonal-proj">
<span class="eqno">(4)<a class="headerlink" href="#equation-feature-orthogonal-proj" title="Link to this equation">¶</a></span>\[
P_{\pmb{w}}^\bot\phi(\pmb{x})=(\pmb{I}-\pmb{ww}^\top)\phi(\pmb{x})
\]</div>
</section>
<section id="id3">
<h2><span class="section-number">2.2. </span>最大协方差的投影<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h2>
<p>  假设有两个多维随机变量<span class="math notranslate nohighlight">\((\pmb{x},\pmb{y})\)</span>，以及各自的投影单位向量<span class="math notranslate nohighlight">\(\pmb{w}_x,\pmb{w}_y\)</span>，则可以将变量投至各自投影方向从而得到两个1维随机变量<span class="math notranslate nohighlight">\(\pmb{w}_x^\top\pmb{x},\pmb{w}_y^\top\pmb{y}\)</span>。这两个变量的协方差可计算如下，</p>
<div class="math notranslate nohighlight" id="equation-proj-covar">
<span class="eqno">(5)<a class="headerlink" href="#equation-proj-covar" title="Link to this equation">¶</a></span>\[
\hat{\mathbb{E}}[\pmb{w}_x^\top\pmb{x}\pmb{w}_y^\top\pmb{y}]=\hat{\mathbb{E}}[\pmb{w}_x^\top\pmb{x}\pmb{y}^\top\pmb{w}_y]=\pmb{w}_x^\top\hat{\mathbb{E}}[\pmb{x}\pmb{y}^\top]\pmb{w}_y=\pmb{w}_x^\top \pmb{C}_{xy}\pmb{w}_y
\]</div>
<p>其中，</p>
<div class="math notranslate nohighlight" id="equation-covar-def">
<span class="eqno">(6)<a class="headerlink" href="#equation-covar-def" title="Link to this equation">¶</a></span>\[
\pmb{C}_{xy}\triangleq \hat{\mathbb{E}}[\pmb{x}\pmb{y}^\top]=\frac1n\sum_{i=1}^n\pmb{x}_i\pmb{y}_i^\top
\]</div>
<p>  投影单位向量<span class="math notranslate nohighlight">\(\pmb{w}_x,\pmb{w}_y\)</span>取什么值才能最大化投影后的协方差<a class="reference internal" href="#equation-proj-covar">(5)</a>呢？即有以下问题，</p>
<div class="math notranslate nohighlight" id="equation-maxi-covar-proj">
<span class="eqno">(7)<a class="headerlink" href="#equation-maxi-covar-proj" title="Link to this equation">¶</a></span>\[\begin{split}
\begin{split}
\max\limits_{\pmb{w}_x,\pmb{w}_y}\quad &amp;\pmb{w}_x^\top \pmb{C}_{xy}\pmb{w}_y\triangleq C(\pmb{w}_x,\pmb{w}_y)\\
\textrm{s.t.}\quad &amp;\lVert\pmb{w}_x\rVert_2=\lVert\pmb{w}_y\rVert_2=1
\end{split}
\end{split}\]</div>
<p>  若对<span class="math notranslate nohighlight">\(\pmb{C}_{xy}\)</span>进行SVD分解，可得到<span class="math notranslate nohighlight">\(\pmb{U,\Sigma,V^\top}=svd(\pmb{C}_{xy})\)</span>，则式<a class="reference internal" href="#equation-maxi-covar-proj">(7)</a>的解为，</p>
<div class="math notranslate nohighlight" id="equation-sol-of-max-covar">
<span class="eqno">(8)<a class="headerlink" href="#equation-sol-of-max-covar" title="Link to this equation">¶</a></span>\[
\boxed{\pmb{w}_x=\pmb{u}_1,\quad\pmb{w}_y=\pmb{v}_1.}
\]</div>
<p>注意：<span class="math notranslate nohighlight">\(\lVert\pmb{Uw}\rVert=\lVert\pmb{w}\rVert\)</span>，且<span class="math notranslate nohighlight">\(\pmb{U,V}\)</span>都是正交矩阵，因此<span class="math notranslate nohighlight">\(\pmb{w}_x\)</span>可以表示为<span class="math notranslate nohighlight">\(\pmb{u}_x\)</span>的形式<span class="math notranslate nohighlight">\(\pmb{Uu}_x\)</span>。</p>
<section id="id4">
<h3><span class="section-number">2.2.1. </span>对偶形式<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h3>
<p>  如果我们不想计算<span class="math notranslate nohighlight">\(\pmb{C}_{xy}\)</span>的SVD分解，例如在核函数定义的特征空间，则可以利用<span class="math notranslate nohighlight">\(\pmb{C}_{xy}\pmb{C}_{xy}^\top\)</span>得到<span class="math notranslate nohighlight">\(\pmb{U}\)</span>以及<span class="math notranslate nohighlight">\(\pmb{C}_{xy}^\top\pmb{C}_{xy}\)</span>得到<span class="math notranslate nohighlight">\(\pmb{V}\)</span>。假设有，</p>
<div class="math notranslate nohighlight" id="equation-dual-represent">
<span class="eqno">(9)<a class="headerlink" href="#equation-dual-represent" title="Link to this equation">¶</a></span>\[
\pmb{C}_{xy}^\top\pmb{C}_{xy}=\frac{1}{n^2}\pmb{Y}^\top\pmb{XX}^\top\pmb{Y}=\frac{1}{n^2}\pmb{Y}^\top\pmb{K}_x\pmb{Y}
\]</div>
<p>与核PCA类似，投影方向<span class="math notranslate nohighlight">\(\pmb{u}_j\)</span>如下，</p>
<div class="math notranslate nohighlight" id="equation-proj-of-direction">
<span class="eqno">(10)<a class="headerlink" href="#equation-proj-of-direction" title="Link to this equation">¶</a></span>\[
\pmb{u}_j=\frac{1}{\sigma_j}\pmb{C}_{xy}\pmb{v}_j
\]</div>
<p>因此，新样本<span class="math notranslate nohighlight">\(\phi(\pmb{x})\)</span>在<span class="math notranslate nohighlight">\(\pmb{u}_j\)</span>上的投影为，</p>
<div class="math notranslate nohighlight" id="equation-new-sample-proj">
<span class="eqno">(11)<a class="headerlink" href="#equation-new-sample-proj" title="Link to this equation">¶</a></span>\[
\pmb{u}_j^\top\phi(\pmb{x})=\frac{1}{n\sigma_j}\pmb{v}_j^\top\pmb{Y}^\top\pmb{X}\phi(\pmb{x})=\sum_{i=1}^n\left(\frac{1}{n\sigma_j}\pmb{Yv}_j\right)\kappa(\pmb{x}_i,\pmb{x})
\]</div>
</section>
</section>
<section id="id5">
<h2><span class="section-number">2.3. </span>广义特征值<a class="headerlink" href="#id5" title="Link to this heading">¶</a></h2>
<p>  广义特征值问题如下，</p>
<div class="math notranslate nohighlight" id="equation-generalised-eigenvalue">
<span class="eqno">(12)<a class="headerlink" href="#equation-generalised-eigenvalue" title="Link to this equation">¶</a></span>\[
\boxed{\pmb{Aw}=\lambda\pmb{Bw}}
\]</div>
<p>其中，<span class="math notranslate nohighlight">\(\pmb{A},\pmb{B}\)</span>均为对称矩阵，此外，<span class="math notranslate nohighlight">\(\pmb{B}\)</span>是正定的。标准特征值问题是上述问题的特殊形式，即<span class="math notranslate nohighlight">\(\pmb{B}=\pmb{I}\)</span>。对于<strong>广义Rayleigh商</strong>(generalized Rayleigh quotient)来说，</p>
<div class="math notranslate nohighlight" id="equation-generalised-rayleigh">
<span class="eqno">(13)<a class="headerlink" href="#equation-generalised-rayleigh" title="Link to this equation">¶</a></span>\[
\rho(\pmb{w})=\frac{\pmb{w}^\top\pmb{Aw}}{\pmb{w}^\top\pmb{Bw}}
\]</div>
<p>广义特征值也是最大化广义Rayleigh商的解，即</p>
<div class="math notranslate nohighlight" id="equation-max-generalised-rayleigh">
<span class="eqno">(14)<a class="headerlink" href="#equation-max-generalised-rayleigh" title="Link to this equation">¶</a></span>\[\begin{split}
\begin{split}
\max\limits_{\pmb{w}}\quad &amp;\pmb{w}^\top\pmb{Aw}\\
\textrm{s.t.}\quad &amp;\pmb{w}^\top\pmb{Bw}=1
\end{split}
\end{split}\]</div>
<p>  式<a class="reference internal" href="#equation-generalised-eigenvalue">(12)</a>可以通过左乘矩阵<span class="math notranslate nohighlight">\(\pmb{B}^{-1}\)</span>转化为标准特征值问题，即</p>
<div class="math notranslate nohighlight" id="equation-transform-generalised-eigenvalue">
<span class="eqno">(15)<a class="headerlink" href="#equation-transform-generalised-eigenvalue" title="Link to this equation">¶</a></span>\[
\pmb{B}^{-1}\pmb{Aw}=\lambda\pmb{w}
\]</div>
<p>然而，需要注意的是：虽然<span class="math notranslate nohighlight">\(\pmb{A},\pmb{B}\)</span>都是对称矩阵，但<span class="math notranslate nohighlight">\(\pmb{B}^{-1}\pmb{A}\)</span>不一定是对称矩阵。<span class="math notranslate nohighlight">\(\pmb{B}\)</span>是正定的对称矩阵，因此，可以分解为<span class="math notranslate nohighlight">\(\pmb{B}^{1/2}\pmb{B}^{1/2}=\pmb{B}\)</span>（可通过特征值分解得到平方根）。</p>
<p>  对式<a class="reference internal" href="#equation-generalised-eigenvalue">(12)</a>左乘<span class="math notranslate nohighlight">\(\pmb{B}^{-1/2}\)</span>，并令<span class="math notranslate nohighlight">\(\boxed{\pmb{w}=\pmb{B}^{-1/2}\pmb{v}}\)</span>，则可得到下标准特征值等式，</p>
<div class="math notranslate nohighlight" id="equation-transform-generalized-eigenvalue-normalise">
<span class="eqno">(16)<a class="headerlink" href="#equation-transform-generalized-eigenvalue-normalise" title="Link to this equation">¶</a></span>\[
\boxed{\pmb{B}^{-1/2}\pmb{AB}^{-1/2}\pmb{v}=\lambda\pmb{v}}
\]</div>
<p>可以验证<span class="math notranslate nohighlight">\(\pmb{B}^{-1/2}\pmb{AB}^{-1/2}=(\pmb{B}^{-1/2}\pmb{AB}^{-1/2})^\top\)</span>，即结果矩阵为对称矩阵。对该矩阵使用特征值分解，即可得到正交的特征向量<span class="math notranslate nohighlight">\(\pmb{v}_i\)</span>及其对应的特征值<span class="math notranslate nohighlight">\(\lambda_i\)</span>，因此，式<a class="reference internal" href="#equation-generalised-eigenvalue">(12)</a>的解为，</p>
<div class="math notranslate nohighlight" id="equation-solution-of-generalized-eigenvaleu">
<span class="eqno">(17)<a class="headerlink" href="#equation-solution-of-generalized-eigenvaleu" title="Link to this equation">¶</a></span>\[
\boxed{\pmb{w}_i=\pmb{B}^{-1/2}\pmb{v}_i}
\]</div>
<p>  <strong>广义特征值的性质</strong>:</p>
<ol class="arabic simple">
<li><p>如果特征值不相同，则在<span class="math notranslate nohighlight">\(\pmb{A},\pmb{B}\)</span>定义的度量(metrics)中，特征向量具有以下正交性：</p></li>
</ol>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\pmb{w}_i^\top\pmb{B}\pmb{w}_j=\delta_{ij}\)</span>，满足此性质的向量<span class="math notranslate nohighlight">\(\pmb{w}_i,\pmb{w}_j\)</span>也称为关于<span class="math notranslate nohighlight">\(\pmb{B}\)</span>的共轭向量。</p></li>
<li><p><span class="math notranslate nohighlight">\(\pmb{w}_i^\top\pmb{A}\pmb{w}_j=\delta_{ij}\lambda_i\)</span></p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>可分解为：<span class="math notranslate nohighlight">\(\pmb{A}=\sum_{i=1}^n\lambda_i\pmb{Bw}_i\pmb{Bw}_i^\top\)</span>。</p></li>
</ol>
</section>
<section id="cca">
<h2><span class="section-number">2.4. </span>CCA<a class="headerlink" href="#cca" title="Link to this heading">¶</a></h2>
<p>  假设有样本集<span class="math notranslate nohighlight">\(S\)</span>,</p>
<div class="math notranslate nohighlight" id="equation-paired-dataset">
<span class="eqno">(18)<a class="headerlink" href="#equation-paired-dataset" title="Link to this equation">¶</a></span>\[
S=\{(\phi_a(\pmb{x}_1),\phi_b(\pmb{x}_1)),(\phi_a(\pmb{x}_2),\phi_b(\pmb{x}_2)),...,(\phi_a(\pmb{x}_n),\phi_b(\pmb{x}_n))\}
\]</div>
<p>这类数据集也称为核函数<span class="math notranslate nohighlight">\(\kappa_a,\kappa_b\)</span>定义特征空间的成对或对齐数据集（paired or aligened dataset）。我们希望在投影方向<span class="math notranslate nohighlight">\(\pmb{w}_a,\pmb{w}_b\)</span>上最大化样本集两个子部分的相关性，即</p>
<div class="math notranslate nohighlight" id="equation-cca-def">
<span class="eqno">(19)<a class="headerlink" href="#equation-cca-def" title="Link to this equation">¶</a></span>\[
\max\rho=\frac{\hat{\mathbb{E}}[\pmb{w}_a^\top\phi_a(\pmb{x})\phi_b(\pmb{x})^\top\pmb{w}_b]}{   \hat{\mathbb{E}}[\pmb{w}_a^\top\phi_a(\pmb{x})\phi_a(\pmb{x})^\top\pmb{w}_a] \hat{\mathbb{E}}[\pmb{w}_b^\top\phi_b(\pmb{x})\phi_b(\pmb{x})^\top\pmb{w}_b]}=\frac{\pmb{w}_a^\top\pmb{C}_{ab}\pmb{w}_b}{\sqrt{\pmb{w}_a^\top\pmb{C}_{aa}\pmb{w}_a\pmb{w}_b^\top\pmb{C}_{bb}\pmb{w}_b}}
\]</div>
<p>  <strong>定义 （canonical correlation analysis, CCA）</strong>. 给定一个成对或对齐数据集及其协方差矩阵<span class="math notranslate nohighlight">\(\pmb{C}_{ab}\)</span>，CCA的目标是寻找投影方向<span class="math notranslate nohighlight">\(\pmb{w}_a,\pmb{w}_b\)</span>最大化投影后的相关性，即，</p>
<div class="math notranslate nohighlight" id="equation-cca-def-normal">
<span class="eqno">(20)<a class="headerlink" href="#equation-cca-def-normal" title="Link to this equation">¶</a></span>\[\begin{split}
\begin{split}
\max\limits_{\pmb{w}_a,\pmb{w}_b}\quad &amp;\pmb{w}_a^\top\pmb{C}_{ab}\pmb{w}_b\\
\textrm{s.t.}\quad &amp;\pmb{w}_a^\top\pmb{C}_{aa}\pmb{w}_a=1,\pmb{w}_b^\top\pmb{C}_{bb}\pmb{w}_b=1
\end{split}
\end{split}\]</div>
<p>  <strong>CCA求解</strong>. 使用拉格朗日乘子法求解，过程如下：</p>
<ol class="arabic simple">
<li><p>定义拉氏函数</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\pmb{w}_a,\pmb{w}_b,\lambda,\mu)=\pmb{w}_a^\top\pmb{C}_{ab}\pmb{w}_b-\frac{\lambda}{2}(\pmb{w}_a^\top\pmb{C}_{aa}\pmb{w}_a-1)-\frac{\mu}{2}(\pmb{w}_b^\top\pmb{C}_{bb}\pmb{w}_b-1)
\]</div>
<ol class="arabic simple" start="2">
<li><p>求偏导，并令偏导=0，解出</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\pmb{C}_{ab}\pmb{w}_b=\lambda\pmb{C}_{aa}\pmb{w}_a,\quad \pmb{C}_{ba}\pmb{w}_a=\mu\pmb{C}_{bb}\pmb{w}_b
\]</div>
<p>将上式的第1个等式乘上<span class="math notranslate nohighlight">\(\pmb{w}_a^\top\)</span>减去第二个等式乘上<span class="math notranslate nohighlight">\(\pmb{w}_b^\top\)</span>，则可以得到，</p>
<div class="math notranslate nohighlight">
\[
\lambda\pmb{w}_a^\top\pmb{C}_{aa}\pmb{w}_a-\lambda\pmb{w}_b^\top\pmb{C}_{bb}\pmb{w}_b=0
\]</div>
<p>这意味着<span class="math notranslate nohighlight">\(\lambda=\mu\)</span>。</p>
<ol class="arabic simple" start="3">
<li><p>解方程组，可得投影向量<span class="math notranslate nohighlight">\(\pmb{w}_a,\pmb{w}_b\)</span></p></li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}\pmb{0}&amp;\pmb{C}_{ab}\\ \pmb{C}_{ba}&amp;\pmb{0} \end{bmatrix}\begin{bmatrix}\pmb{w}_a\\ \pmb{w}_b\end{bmatrix}=\lambda\begin{bmatrix}\pmb{C}_{aa}&amp;\pmb{0}\\ \pmb{0}&amp;\pmb{C}_{bb} \end{bmatrix}\begin{bmatrix}\pmb{w}_a\\ \pmb{w}_b\end{bmatrix}
\end{split}\]</div>
<p>可以看出，上式是一个广义特征值问题，即</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pmb{A}\begin{bmatrix}\pmb{w}_a\\ \pmb{w}_b\end{bmatrix}=\lambda\pmb{B}\begin{bmatrix}\pmb{w}_a\\ \pmb{w}_b\end{bmatrix}
\end{split}\]</div>
<section id="kcca">
<h3><span class="section-number">2.4.1. </span>KCCA<a class="headerlink" href="#kcca" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>CCA的对偶形式</strong></p></li>
</ul>
<p>  考虑<span class="math notranslate nohighlight">\(\pmb{w}_a,\pmb{w}_b\)</span>分别为数据矩阵<span class="math notranslate nohighlight">\(\pmb{X}_a,\pmb{X}_b\)</span>的所有样本线性组合，即</p>
<div class="math notranslate nohighlight" id="equation-kcca-proj-def">
<span class="eqno">(21)<a class="headerlink" href="#equation-kcca-proj-def" title="Link to this equation">¶</a></span>\[
\pmb{w}_a=\pmb{X}_a^\top\pmb{\alpha}_a,\quad \pmb{w}_b=\pmb{X}_b^\top\pmb{\alpha}_b
\]</div>
<p>将<a class="reference internal" href="#equation-kcca-proj-def">(21)</a>代回式<a class="reference internal" href="#equation-cca-def-normal">(20)</a>，则可得到，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\max\limits_{\pmb{\alpha}_a,\pmb{\alpha}_b}\quad &amp;\pmb{\alpha}_a^\top\pmb{X}_a\pmb{X}_a^\top\pmb{X}_b\pmb{X}_b^\top\pmb{\alpha}_b\\
\textrm{s.t.}\quad &amp;\pmb{\alpha}_a^\top\pmb{X}_a\pmb{X}_a^\top\pmb{X}_a\pmb{X}_a^\top\pmb{\alpha}_a=1,\quad \pmb{\alpha}_b^\top\pmb{X}_b\pmb{X}_b^\top\pmb{X}_b\pmb{X}_b^\top\pmb{\alpha}_b=1
\end{split}
\end{split}\]</div>
<p>则可以得到Kernel CCA的一般形式，即</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\max\limits_{\pmb{\alpha}_a,\pmb{\alpha}_b}\quad &amp;\pmb{\alpha}_a^\top\pmb{K}_a\pmb{K}_b\pmb{\alpha}_b\\
\textrm{s.t.}\quad &amp;\pmb{\alpha}_a^\top\pmb{K}_a^2\pmb{\alpha}_a=1,\quad \pmb{\alpha}_b^\top\pmb{K}_b^2\pmb{\alpha}_b=1
\end{split}
\end{split}\]</div>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../index.html">目录</a></h3>
    <ul>
<li><a class="reference internal" href="#">2. 核函数基础2</a><ul>
<li><a class="reference internal" href="#id2">2.1. 投影</a></li>
<li><a class="reference internal" href="#id3">2.2. 最大协方差的投影</a><ul>
<li><a class="reference internal" href="#id4">2.2.1. 对偶形式</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id5">2.3. 广义特征值</a></li>
<li><a class="reference internal" href="#cca">2.4. CCA</a><ul>
<li><a class="reference internal" href="#kcca">2.4.1. KCCA</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>上一主题</h4>
    <p class="topless"><a href="base.html"
                          title="上一章"><span class="section-number">1. </span>核函数基础</a></p>
  </div>
  <div>
    <h4>下一主题</h4>
    <p class="topless"><a href="RKHS.html"
                          title="下一章"><span class="section-number">3. </span>再生核希尔伯特空间</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/kernel/base2.md.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">快速搜索</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="提交" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="Related">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="总索引"
             >索引</a></li>
        <li class="right" >
          <a href="RKHS.html" title="3. 再生核希尔伯特空间"
             >下一页</a> |</li>
        <li class="right" >
          <a href="base.html" title="1. 核函数基础"
             >上一页</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Machine Learning Fundation 1.0 文档</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">2. </span>核函数基础2</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; 版权所有 2022-2024, SSPUIIP.
      由 <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3创建。
    </div>
  </body>
</html>