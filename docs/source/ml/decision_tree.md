# 决策树

&emsp;&emsp;**决策树**是一种模拟人决策过程的树形结构。例如：如果有以下一段对话，
>   女儿：多大年纪了？<br>
  母亲：26。<br>
  女儿：长的帅不帅？<br>
  母亲：挺帅的。<br>
  女儿：收入高不？<br>
  母亲：不算很高，中等情况。<br>
  女儿：是公务员不？<br>
  母亲：是，在税务局上班呢。<br>
  女儿：那好，我去见见。<br>

上述对话体现了人类做出见/不见决策的一个过程。根据对话的顺序，该决策过程可以用下图来刻画。

```{mermaid}
---
caption: Fig 1. 决策过程模拟树。  
align: center
---
%%{
    init: {
        'theme':'base',
        'themeVariables': {
            'fontSize': 8px
        }
    }
}%%
flowchart LR
  id1((年龄)) -- <=30--> id2((长相))
  id1 -- >30 --> id3[不见]
  id2 -- 帅 --> id4((收入))
  id2 -- 不帅 --> id5[不见]
  id4 -- 高 --> id6[见]
  id4 -- 中 --> id7((公务员))
  id4 -- 低 --> id8[不见]
  id7 -- 是 --> id9[见]
  id7 -- 不是 --> id10[不见]
 
```

&emsp;&emsp;**决策树在构建过程中有个基本问题需要解答**。如上图所示，为什么选择年龄做为第1个分裂的结点而不是其它特征？也就是如何确定分裂特征的顺序？这一问题也称为**特征选择**问题。

&emsp;&emsp;依据特征选择策略的不同，决策树算法大至有ID3,C4.5,CART等不同的决策树构建算法。这些算法的基本流程框架如下所示：

|决策树学习算法基本框架|
|:---|
|**输入**: 训练集$D=\{(\pmb{x}_1,y_1),(\pmb{x}_2,y_2),...,(\pmb{x}_m,y_m)\}$，属性集$A=\{a_1,a_2,...,a_d\}$ |
|**输出**: 以root为根的一棵决策树|
|**过程**: decitionTree(D,A)|
|1:生成结点root|
|2: **if**($D$中样本属于同一类别$C$){ |
|3: &emsp;&emsp; return; |
|4: }|
|5: **if**($A=\emptyset$ or $D$中样本在属性$A$取值一致){|
|6: &emsp;&emsp;将root标记为叶结点，类别为$D$中样本数最多的类; return;|
|7:}|
|8:根据属性挑选规则，在属性集$A$中挑选最优属性$a$;|
|9: **for**($a$的每一个属性值$a^v$){|
|10:&emsp;&emsp;为root生成一个分支结点，该结点的样本集$D_v$为$a==a^v$的所有样本;|
|11:&emsp;&emsp;|
|12:|
|13:|
|14:|
|15:|
|16:|
