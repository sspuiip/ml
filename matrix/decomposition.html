<!DOCTYPE html>

<html lang="zh-CN" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7. 矩阵分解 &#8212; Machine Learning Fundation 1.0 文档</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css?v=279e0f84" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="../_static/documentation_options.js?v=f115507d"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="../_static/mathjax/tex-chtml.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="1. 粗糙集基础" href="../roughset/roughbase.html" />
    <link rel="prev" title="6. 子空间分析" href="subspace.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="Related">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="总索引"
             accesskey="I">索引</a></li>
        <li class="right" >
          <a href="../roughset/roughbase.html" title="1. 粗糙集基础"
             accesskey="N">下一页</a> |</li>
        <li class="right" >
          <a href="subspace.html" title="6. 子空间分析"
             accesskey="P">上一页</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Machine Learning Fundation 1.0 文档</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">7. </span>矩阵分解</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1><span class="section-number">7. </span>矩阵分解<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h1>
<section id="qr">
<h2><span class="section-number">7.1. </span>QR分解<a class="headerlink" href="#qr" title="Link to this heading">¶</a></h2>
<section id="id2">
<h3><span class="section-number">7.1.1. </span>QR的一般形式<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<p>  对于一般矩阵<span class="math notranslate nohighlight">\(\pmb{A}_{m\times n}(m\ge n)\)</span>，可以分解为，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pmb{A}_{m\times n}=\pmb{Q}_{m\times m}\pmb{R}_{m\times n}=\pmb{Q}\left[ \begin{array}{c}\pmb{R}_1\\\pmb{0}\end{array}\right]=\left[ \pmb{Q}_1\quad \pmb{Q}_2\right]\left[ \begin{array}{c}\pmb{R}_1\\\pmb{0}\end{array}\right]=\pmb{Q}_1\pmb{R}_1
\end{split}\]</div>
<p>其中<span class="math notranslate nohighlight">\(\pmb{Q}\)</span>为正交矩阵<span class="math notranslate nohighlight">\(\pmb{Q}^\top=\pmb{Q}^{-1}\)</span>（列向量正交），<span class="math notranslate nohighlight">\(\pmb{R}\)</span>为上三角矩阵，即<span class="math notranslate nohighlight">\(\pmb{R}_1\)</span>为<span class="math notranslate nohighlight">\(n\times n\)</span>的上三角矩阵。一般来说，<span class="math notranslate nohighlight">\(\pmb{Q}\)</span>矩阵的前<span class="math notranslate nohighlight">\(k(1\le k\le n)\)</span>个列向量构建了矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>的前<span class="math notranslate nohighlight">\(k\)</span>列张成的一个标准正交基。</p>
<ul class="simple">
<li><p><strong>例</strong>1</p></li>
</ul>
<div class="highlight-matlab notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span><span class="n">A</span><span class="p">=[</span><span class="mi">1</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span><span class="n">2</span><span class="w"> </span><span class="s">4</span><span class="w"> </span><span class="s">6</span><span class="p">;</span><span class="n">1</span><span class="w"> </span><span class="s">1</span><span class="w"> </span><span class="s">1]</span>
<span class="o">&gt;&gt;&gt;</span><span class="p">[</span><span class="n">Q</span><span class="p">,</span><span class="n">R</span><span class="p">]=</span><span class="nb">qr</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span><span class="n">Q</span>

<span class="w">   </span><span class="o">-</span><span class="mf">0.4082</span><span class="w">   </span><span class="o">-</span><span class="mf">0.1826</span><span class="w">   </span><span class="o">-</span><span class="mf">0.8944</span>
<span class="w">   </span><span class="o">-</span><span class="mf">0.8165</span><span class="w">   </span><span class="o">-</span><span class="mf">0.3651</span><span class="w">    </span><span class="mf">0.4472</span>
<span class="w">   </span><span class="o">-</span><span class="mf">0.4082</span><span class="w">    </span><span class="mf">0.9129</span><span class="w">   </span><span class="o">-</span><span class="mf">0.0000</span>
<span class="w">   </span>
<span class="o">&gt;&gt;&gt;</span><span class="n">R</span>

<span class="w">   </span><span class="o">-</span><span class="mf">2.4495</span><span class="w">   </span><span class="o">-</span><span class="mf">4.4907</span><span class="w">   </span><span class="o">-</span><span class="mf">6.5320</span>
<span class="w">         </span><span class="mi">0</span><span class="w">   </span><span class="o">-</span><span class="mf">0.9129</span><span class="w">   </span><span class="o">-</span><span class="mf">1.8257</span>
<span class="w">         </span><span class="mi">0</span><span class="w">         </span><span class="mi">0</span><span class="w">    </span><span class="mf">0.0000</span>
<span class="w">         </span>
<span class="o">&gt;&gt;&gt;</span><span class="n">Q1</span><span class="p">=</span><span class="n">Q</span><span class="p">(:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">)</span>

<span class="w">   </span><span class="o">-</span><span class="mf">0.4082</span><span class="w">   </span><span class="o">-</span><span class="mf">0.1826</span>
<span class="w">   </span><span class="o">-</span><span class="mf">0.8165</span><span class="w">   </span><span class="o">-</span><span class="mf">0.3651</span>
<span class="w">   </span><span class="o">-</span><span class="mf">0.4082</span><span class="w">    </span><span class="mf">0.9129</span>
<span class="w">   </span>
<span class="o">&gt;&gt;&gt;</span><span class="n">R1</span><span class="p">=</span><span class="n">R</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">,:)</span>

<span class="w">   </span><span class="o">-</span><span class="mf">2.4495</span><span class="w">   </span><span class="o">-</span><span class="mf">4.4907</span><span class="w">   </span><span class="o">-</span><span class="mf">6.5320</span>
<span class="w">         </span><span class="mi">0</span><span class="w">   </span><span class="o">-</span><span class="mf">0.9129</span><span class="w">   </span><span class="o">-</span><span class="mf">1.8257</span>
<span class="w">         </span>
<span class="o">&gt;&gt;&gt;</span><span class="n">Q1</span><span class="o">*</span><span class="n">R1</span>

<span class="w">    </span><span class="mf">1.0000</span><span class="w">    </span><span class="mf">2.0000</span><span class="w">    </span><span class="mf">3.0000</span>
<span class="w">    </span><span class="mf">2.0000</span><span class="w">    </span><span class="mf">4.0000</span><span class="w">    </span><span class="mf">6.0000</span>
<span class="w">    </span><span class="mf">1.0000</span><span class="w">    </span><span class="mf">1.0000</span><span class="w">    </span><span class="mf">1.0000</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>注意</strong></p></li>
</ul>
<p>  当矩阵列不满秩时，可以使用<code class="docutils literal notranslate"><span class="pre">[Q,R,P]=qr(A)</span></code>来分解，且满足<span class="math notranslate nohighlight">\(\pmb{A}*\pmb{P}=\pmb{Q}*\pmb{R}\)</span>其中<span class="math notranslate nohighlight">\(\pmb{P}\)</span>为转换矩阵。若<span class="math notranslate nohighlight">\(\pmb{A}=[\pmb{x}_1,\pmb{x}_2,...,\pmb{x}_n]\)</span>为数据矩阵时，<span class="math notranslate nohighlight">\(\pmb{P}\)</span>的作用等价于样本重新排列顺序。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="go">&gt;&gt;&gt;C=[1 1 2;2 1 4;3 1 6]</span>

<span class="go">     1     1     2</span>
<span class="go">     2     1     4</span>
<span class="go">     3     1     6</span>

<span class="go">&gt;&gt;&gt;[Q,R,P]=qr(C)</span>

<span class="go">Q =</span>
<span class="go">   -0.2673    0.8729    0.4082</span>
<span class="go">   -0.5345    0.2182   -0.8165</span>
<span class="go">   -0.8018   -0.4364    0.4082</span>

<span class="go">R =</span>
<span class="go">   -7.4833   -1.6036   -3.7417</span>
<span class="go">         0    0.6547    0.0000</span>
<span class="go">         0         0    0.0000</span>
<span class="go">         </span>
<span class="go">P =</span>
<span class="go">     0     0     1</span>
<span class="go">     0     1     0</span>
<span class="go">     1     0     0</span>

<span class="go">&gt;&gt;&gt;Q(:,1:rank(R)) * R(1:rank(R),:)</span>
<span class="go">ans =</span>

<span class="go">    2.0000    1.0000    1.0000</span>
<span class="go">    4.0000    1.0000    2.0000</span>
<span class="go">    6.0000    1.0000    3.0000</span>

<span class="go">&gt;&gt;&gt;C*P</span>
<span class="go">ans =</span>

<span class="go">     2     1     1</span>
<span class="go">     4     1     2</span>
<span class="go">     6     1     3</span>
</pre></div>
</div>
</section>
<section id="qrgram-schmidt">
<h3><span class="section-number">7.1.2. </span>QR分解的Gram-Schmidt正交化方法<a class="headerlink" href="#qrgram-schmidt" title="Link to this heading">¶</a></h3>
<p>  考虑矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>，即，</p>
<div class="math notranslate nohighlight">
\[
\pmb{A}=\left[\pmb{a}_1,\pmb{a}_2,...,\pmb{a}_n \right]
\]</div>
<p>Gram-Schmidt正交化过程如下，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\pmb{u}_1&amp;=\pmb{a}_1,\quad \pmb{e}_1=\frac{\pmb{u}_1}{\Vert \pmb{u}_1\Vert}\\
\pmb{u}_2&amp;=\pmb{a}_2-\langle\pmb{a}_2,\pmb{e}_1\rangle\pmb{e}_1,\quad\pmb{e}_2=\frac{\pmb{u}_2}{\Vert \pmb{u}_2\Vert}\\
&amp;\vdots\\
\pmb{u}_{k+1}&amp;=\pmb{a}_{k+1}-\sum_{i=1}^k\langle\pmb{a}_{k+1},\pmb{e}_i\rangle\pmb{e}_i\quad\quad\pmb{e}_{k+1}=\frac{\pmb{u}_{k+1}}{\Vert \pmb{u}_{k+1}\Vert}
\end{split}
\end{split}\]</div>
<p>则QR分解结果为，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pmb{A}=\left[\pmb{a}_1,\pmb{a}_2,...,\pmb{a}_n \right]=\left[\pmb{e}_1,\pmb{e}_2,...,\pmb{e}_n \right]\begin{bmatrix}\langle\pmb{a}_1,\pmb{e}_1\rangle&amp; \langle\pmb{a}_2,\pmb{e}_1\rangle &amp;\cdots &amp;\langle\pmb{a}_n,\pmb{e}_1\rangle\\ 0&amp; \langle\pmb{a}_2,\pmb{e}_2\rangle &amp;\cdots &amp;\langle\pmb{a}_n,\pmb{e}_2\rangle\\ \vdots&amp; \vdots&amp; \ddots &amp; \vdots &amp;\\ 0&amp; 0&amp;\cdots&amp;\langle\pmb{a}_n,\pmb{e}_n\rangle \end{bmatrix}=\pmb{QR}
\end{split}\]</div>
<p>其中，<span class="math notranslate nohighlight">\(\langle \pmb{e}_i,\pmb{a}_i\rangle=\Vert\pmb{u}_i\Vert\)</span>。</p>
<p>  注意，</p>
<div class="math notranslate nohighlight">
\[
\langle \pmb{e}_i,\pmb{a}_i\rangle=\left\langle\frac{\pmb{u}_i}{\Vert\pmb{u}_i\Vert},\pmb{u}_i+\sum_{j=1}^{i-1}\langle\pmb{a}_i,\pmb{e}_j\rangle\pmb{e}_j\right\rangle=\left\langle\frac{\pmb{u}_i}{\Vert\pmb{u}_i\Vert},\pmb{u}_i\right\rangle=\Vert\pmb{u}_i\Vert
\]</div>
<p>以及，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\pmb{a}_i&amp;=\sum_{j=1}^{i-1}\langle\pmb{a}_i,\pmb{e}_j\rangle\pmb{e}_j+\pmb{u}_i\\
&amp;=\sum_{j=1}^{i-1}\langle\pmb{a}_i,\pmb{e}_j\rangle\pmb{e}_j+\frac{\pmb{u}_i}{\Vert\pmb{u}_i\Vert}\Vert\pmb{u}_i\Vert\\
&amp;=\sum_{j=1}^{i-1}\langle\pmb{a}_i,\pmb{e}_j\rangle\pmb{e}_j+\pmb{e}_i\langle \pmb{e}_i,\pmb{a}_i\rangle\\
\end{split}
\end{split}\]</div>
</section>
</section>
<section id="id3">
<h2><span class="section-number">7.2. </span>特征值分解<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h2>
<section id="id4">
<h3><span class="section-number">7.2.1. </span>方阵的特征值分解<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h3>
<p>  若方阵<span class="math notranslate nohighlight">\(\pmb{A}_{m\times m}\)</span>可对角化，则有，</p>
<div class="math notranslate nohighlight">
\[
\pmb{A}=\pmb{X}\pmb{\Lambda}\pmb{X}^{-1}
\]</div>
<p>  矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>的特征向量是经过矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>变换后方向保持不变的向量，而特征值为这个变换中特征向量的缩放因子，即矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>对特征向量<span class="math notranslate nohighlight">\(\pmb{x}\)</span>的变换等于特征向量与特征值的乘积。</p>
<div class="math notranslate nohighlight">
\[
\pmb{Ax}=\lambda \pmb{x}
\]</div>
<p>  令，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pmb{X}=\begin{pmatrix}|&amp;|&amp;\dots&amp;|\\\pmb{x}_1&amp;\pmb{x}_2&amp;\dots&amp;\pmb{x}_n\\|&amp;|&amp;\dots&amp;| \end{pmatrix},\quad \pmb{\Lambda}=\begin{pmatrix}\lambda_1&amp;&amp;&amp;\\&amp;\lambda_2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_n \end{pmatrix}
\end{split}\]</div>
<p>可以得到，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}\pmb{AX}&amp;=A\begin{pmatrix}|&amp;|&amp;\dots&amp;|\\\pmb{x}_1&amp;\pmb{x}_2&amp;\dots&amp;\pmb{x}_n\\|&amp;|&amp;\dots&amp;| \end{pmatrix}\\&amp;=\begin{pmatrix}|&amp;|&amp;\dots&amp;|\\\lambda_1\pmb{x}_1&amp;\lambda_2\pmb{x}_2&amp;\dots&amp;\lambda_n\pmb{x}_n\\|&amp;|&amp;\dots&amp;| \end{pmatrix}\\&amp;=\begin{pmatrix}|&amp;|&amp;\dots&amp;|\\\pmb{x}_1&amp;\pmb{x}_2&amp;\dots&amp;\pmb{x}_n\\|&amp;|&amp;\dots&amp;| \end{pmatrix}\begin{pmatrix}\lambda_1&amp;&amp;&amp;\\&amp;\lambda_2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_n \end{pmatrix}\\&amp;=\pmb{X\Lambda}\end{split}
\end{split}\]</div>
<p>最终，我们可以得到结论（特征向量线性无关，故<span class="math notranslate nohighlight">\(\pmb{X}^{-1}\)</span>存在），</p>
<div class="math notranslate nohighlight">
\[
\pmb{A}=\pmb{X}\pmb{\Lambda} \pmb{X}^{-1}
\]</div>
<section id="id5">
<h4><span class="section-number">7.2.1.1. </span>对称矩阵的特征值分解<a class="headerlink" href="#id5" title="Link to this heading">¶</a></h4>
<p>  任意对称实矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>可分解为，</p>
<div class="math notranslate nohighlight">
\[
\pmb{A}=\pmb{Q}\pmb{\Lambda} \pmb{Q}^{-1}=\pmb{Q}\pmb{\Lambda} \pmb{Q}^\top.
\]</div>
<p>  对称矩阵有一个<strong>非常重要的性质</strong>：</p>
<blockquote>
<div><p>对称矩阵的特征向量是正交向量，即<span class="math notranslate nohighlight">\(\langle\pmb{x}_i, \pmb{x}_j\rangle=0,\forall i\neq j\)</span>。</p>
</div></blockquote>
<p>  <strong>证</strong>：假设<span class="math notranslate nohighlight">\(\lambda_1,\lambda_2,\pmb{x}_1,\pmb{x}_2\)</span>为对称矩阵<span class="math notranslate nohighlight">\(S\)</span>的任意互不相等的特征值和特征向量，那么，</p>
<div class="math notranslate nohighlight">
\[
\lambda_1\langle\pmb{x}_i, \pmb{x}_j\rangle=\langle\pmb{Ax}_1, \pmb{x}_2\rangle=\pmb{x}_1^\top \pmb{Ax}_2=\pmb{x}_1^\top\lambda_2\pmb{x}_2=\lambda_2\langle\pmb{x}_1, \pmb{x}_2\rangle
\]</div>
<p>等式左边减去右边，得</p>
<div class="math notranslate nohighlight">
\[
(\lambda_1-\lambda_2)\langle\pmb{x}_1, \pmb{x}_2\rangle=0.
\]</div>
<p>  由于<span class="math notranslate nohighlight">\(\lambda_1\neq\lambda_2\)</span>，因此只能<span class="math notranslate nohighlight">\(\langle\pmb{x}_1, \pmb{x}_2\rangle=0\)</span>，即对称矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>的任意不相同的特征向量是正交的。于是，我们可以得到一个<strong>重要结论</strong>：</p>
<blockquote>
<div><p>对称矩阵可以分解为两个由正交向量组成的矩阵与其对角阵的乘积，即<span class="math notranslate nohighlight">\(\pmb{A}=\pmb{Q}\pmb{\Lambda} \pmb{Q}^{-1}=\pmb{Q}\pmb{\Lambda} \pmb{Q}^\top\)</span>。</p>
</div></blockquote>
</section>
</section>
</section>
<section id="id6">
<h2><span class="section-number">7.3. </span>奇异值分解<a class="headerlink" href="#id6" title="Link to this heading">¶</a></h2>
<p>  对于<span class="math notranslate nohighlight">\(m\times n\)</span>的矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>，没有特征值的定义。因此，不能进行特征值分解。但可以使用奇异值分解，即</p>
<div class="math notranslate nohighlight">
\[
\pmb{A}=\pmb{U}\pmb{\Sigma} \pmb{V}^\top=\sum_{i=1}\sigma_i\pmb{u}_i\pmb{v}_i^\top
\]</div>
<p>其中<span class="math notranslate nohighlight">\(\pmb{U}=(\pmb{u}_1,\pmb{u}_2,...,\pmb{u}_m)\)</span>为<span class="math notranslate nohighlight">\(m\times m\)</span>的正交矩阵，<span class="math notranslate nohighlight">\(\pmb{u}_i\)</span>称为矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>的左奇异向量。<span class="math notranslate nohighlight">\(\pmb{V}=(\pmb{v}_1,\pmb{v}_2,...,\pmb{v}_n)\)</span>为<span class="math notranslate nohighlight">\(n\times n\)</span>的正交矩阵，<span class="math notranslate nohighlight">\(\pmb{v}_i\)</span>称为矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>的右奇异向量。<span class="math notranslate nohighlight">\(\pmb{\Sigma}\)</span>的主对角线上的元素<span class="math notranslate nohighlight">\(\sigma_i\)</span>称为奇异值。</p>
<p>  奇异值分解(SVD)的目标就是找到参数<span class="math notranslate nohighlight">\(\pmb{U},\pmb{V}\)</span>和奇异值矩阵<span class="math notranslate nohighlight">\(\pmb{\Sigma}\)</span>。<span class="math notranslate nohighlight">\(\pmb{u}_i,\pmb{v}_i\)</span>都是正交向量且满足，</p>
<div class="math notranslate nohighlight">
\[
\pmb{Av}_i=\sigma_i\pmb{u}_i
\]</div>
<p>也就是说，一个<span class="math notranslate nohighlight">\(n\)</span>维向量<span class="math notranslate nohighlight">\(\pmb{v}\)</span>经过矩阵<span class="math notranslate nohighlight">\(\pmb{A}\)</span>的变换<strong>等于</strong>一个<span class="math notranslate nohighlight">\(m\)</span>维向量<span class="math notranslate nohighlight">\(\pmb{u}\)</span>经过奇异值<span class="math notranslate nohighlight">\(\sigma\)</span>的缩放。</p>
<section id="svd">
<h3><span class="section-number">7.3.1. </span>SVD参数求解<a class="headerlink" href="#svd" title="Link to this heading">¶</a></h3>
<p>  SVD参数一般通过<span class="math notranslate nohighlight">\(\pmb{AA}^\top\)</span>求<span class="math notranslate nohighlight">\(\pmb{U}\)</span>,<span class="math notranslate nohighlight">\(\pmb{A}^\top\pmb{A}\)</span>求<span class="math notranslate nohighlight">\(\pmb{V}\)</span>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\pmb{AA}^\top&amp;=\pmb{U}\pmb{\Sigma} \pmb{V}^\top \pmb{V\Sigma U}^\top=\pmb{U\Sigma}^2 \pmb{U}^\top\\ 
\pmb{A}^\top\pmb{A}&amp;=\pmb{V}\pmb{\Sigma U}^\top \pmb{U\Sigma V}^\top=\pmb{V\Sigma}^2\pmb{V}^\top
\end{split}
\end{split}\]</div>
<p>由于上述矩阵均为对称矩阵，因此，可以使用特征值分解求得矩阵<span class="math notranslate nohighlight">\(\pmb{U},\pmb{V}\)</span>。</p>
<p>  <span class="math notranslate nohighlight">\(\pmb{\Sigma}\)</span>与<span class="math notranslate nohighlight">\(\pmb{AA}^\top,\pmb{A}^\top\pmb{A}\)</span>的关系，可以求得奇异值。</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\pmb{AA}^\top\)</span>与<span class="math notranslate nohighlight">\(\pmb{A}^\top\pmb{A}\)</span>的特征值是相等的。</p>
</div></blockquote>
<p>  <strong>证</strong>：<span class="math notranslate nohighlight">\(\pmb{AA}^\top\pmb{x}=\lambda \pmb{x}\)</span>，可以得到<span class="math notranslate nohighlight">\(\pmb{A}^\top\pmb{AA}^\top\pmb{x}=\lambda \pmb{A}^\top\pmb{x}\)</span>，于是有，<span class="math notranslate nohighlight">\(\pmb{A}^\top\pmb{A}(\pmb{A}^\top\pmb{x})=\lambda(\pmb{A}^\top\pmb{x})\)</span>，即，<span class="math notranslate nohighlight">\(\lambda\)</span>为<span class="math notranslate nohighlight">\(\pmb{A}^\top\pmb{A}\)</span>的特征值，<span class="math notranslate nohighlight">\(\pmb{A}^\top\pmb{x}\)</span>为新的特征向量。</p>
<p>  令<span class="math notranslate nohighlight">\(\lambda_i\)</span>为<span class="math notranslate nohighlight">\(\pmb{A}^\top\pmb{A}\)</span>的特征值，则，奇异值<span class="math notranslate nohighlight">\(\sigma_i=\sqrt{\lambda_i}\)</span>。</p>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../index.html">目录</a></h3>
    <ul>
<li><a class="reference internal" href="#">7. 矩阵分解</a><ul>
<li><a class="reference internal" href="#qr">7.1. QR分解</a><ul>
<li><a class="reference internal" href="#id2">7.1.1. QR的一般形式</a></li>
<li><a class="reference internal" href="#qrgram-schmidt">7.1.2. QR分解的Gram-Schmidt正交化方法</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id3">7.2. 特征值分解</a><ul>
<li><a class="reference internal" href="#id4">7.2.1. 方阵的特征值分解</a><ul>
<li><a class="reference internal" href="#id5">7.2.1.1. 对称矩阵的特征值分解</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#id6">7.3. 奇异值分解</a><ul>
<li><a class="reference internal" href="#svd">7.3.1. SVD参数求解</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>上一主题</h4>
    <p class="topless"><a href="subspace.html"
                          title="上一章"><span class="section-number">6. </span>子空间分析</a></p>
  </div>
  <div>
    <h4>下一主题</h4>
    <p class="topless"><a href="../roughset/roughbase.html"
                          title="下一章"><span class="section-number">1. </span>粗糙集基础</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/matrix/decomposition.md.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">快速搜索</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="提交" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="Related">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="总索引"
             >索引</a></li>
        <li class="right" >
          <a href="../roughset/roughbase.html" title="1. 粗糙集基础"
             >下一页</a> |</li>
        <li class="right" >
          <a href="subspace.html" title="6. 子空间分析"
             >上一页</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Machine Learning Fundation 1.0 文档</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">7. </span>矩阵分解</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; 版权所有 2022-2024, SSPUIIP.
      由 <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3创建。
    </div>
  </body>
</html>