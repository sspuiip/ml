<!DOCTYPE html>

<html lang="zh-CN" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2. Bregman divergence &#8212; Machine Learning Fundation 1.0 文档</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css?v=601dbdee" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <script src="../_static/documentation_options.js?v=f115507d"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="../_static/mathjax/tex-chtml.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="3. 信息熵" href="entropy.html" />
    <link rel="prev" title="1. 不确定模型" href="statistic_model.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="总索引"
             accesskey="I">索引</a></li>
        <li class="right" >
          <a href="entropy.html" title="3. 信息熵"
             accesskey="N">下一页</a> |</li>
        <li class="right" >
          <a href="statistic_model.html" title="1. 不确定模型"
             accesskey="P">上一页</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Machine Learning Fundation 1.0 文档</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">2. </span>Bregman divergence</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="bregman-divergence">
<h1><span class="section-number">2. </span>Bregman divergence<a class="headerlink" href="#bregman-divergence" title="Link to this heading">¶</a></h1>
<p>The surprising result - due to <a class="reference external" href="https://ieeexplore.ieee.org/document/1459065">Banerjee, Gou, and Wang 2005</a> is the following,</p>
<blockquote>
<div><p>If you have some abstract way of measuring the “distance” between any two points and, for any choice of distribution over points the mean point minimises the average distance to all the others, then your distance measure must be a Bregman divergence.</p>
</div></blockquote>
<section id="squared-euclidean-distance">
<h2><span class="section-number">2.1. </span>Squared Euclidean Distance<a class="headerlink" href="#squared-euclidean-distance" title="Link to this heading">¶</a></h2>
<p>One member of the Bregman divergence family is the squared Euclidean distance (SED), i.e.,</p>
<div class="math notranslate nohighlight">
\[
d^2(\pmb{x},\pmb{y})=\sum_{i=1}^n(x_i-y_i)^2
\]</div>
<p>SED can be represented as follow,</p>
<div class="math notranslate nohighlight">
\[
d^2(\pmb{x},\pmb{y})=\Vert \pmb{x}-\pmb{y}\Vert^2=\Vert \pmb{x}\Vert^2-\Vert \pmb{y}\Vert^2-\langle 2\pmb{y},\pmb{x}-\pmb{y}\rangle
\]</div>
<p>Obviously, the derivative of <span class="math notranslate nohighlight">\(\Vert \pmb{y}\Vert^2\)</span> is <span class="math notranslate nohighlight">\(2\pmb{y}\)</span>. Now, we take a look on the term <span class="math notranslate nohighlight">\(\Vert \pmb{y}\Vert^2+\langle 2\pmb{y},\pmb{x}-\pmb{y}\rangle\)</span> which is the value of the tangent line to <span class="math notranslate nohighlight">\(\Vert \pmb{y}\Vert^2\)</span> at <span class="math notranslate nohighlight">\(\pmb{y}\)</span> evaluated at <span class="math notranslate nohighlight">\(\pmb{x}\)</span>. This means the whole expression is just the difference between the function <span class="math notranslate nohighlight">\(f(\pmb{x})=\Vert \pmb{x}\Vert^2\)</span> at <span class="math notranslate nohighlight">\(\pmb{x}\)</span> and the value of <span class="math notranslate nohighlight">\(f\)</span>’s tangent at <span class="math notranslate nohighlight">\(\pmb{y}\)</span> evaluated at <span class="math notranslate nohighlight">\(\pmb{x}\)</span>. That is,</p>
<div class="math notranslate nohighlight">
\[
d^2(\pmb{x},\pmb{y})=f(\pmb{x})-\underbrace{(f(\pmb{y})+\langle 2\pmb{y},\pmb{x}-\pmb{y}\rangle)}_{\textrm{Tangent of $f$ at $\pmb{y}$ evaluated at $\pmb{x}$}}
\]</div>
<p><img alt="Bregman Divergence" src="../_images/bregman.png" /></p>
</section>
<section id="bregman-divergences">
<h2><span class="section-number">2.2. </span>Bregman divergences<a class="headerlink" href="#bregman-divergences" title="Link to this heading">¶</a></h2>
<p>So far, the only one constraint which is placed on the distance measure <span class="math notranslate nohighlight">\(d^2\)</span> is that it be non-negative for all possible choices of point <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>. This is equivalent to the function <span class="math notranslate nohighlight">\(f\)</span> always sitting above its tangent, that is,</p>
<div class="math notranslate nohighlight">
\[
f(x)\ge f(y)+\langle \nabla f(y),x-y\rangle, \quad \forall x,y\in\mathbb{R}^n.
\]</div>
<p>Obviously, the above condition placed on the function <span class="math notranslate nohighlight">\(f\)</span> is equivalent to functions <span class="math notranslate nohighlight">\(f\)</span> being convex. This means that we can derive a distance measure <span class="math notranslate nohighlight">\(d_f\)</span> that has a similar stucture to the SED by simply choosing a convex function <span class="math notranslate nohighlight">\(f\)</span> and defining,</p>
<div class="math notranslate nohighlight">
\[
\boxed{d_f(x,y)=f(x)-f(y)-\langle \nabla f(y), x-y\rangle}
\]</div>
<p>Distance defined like this are precisely the <strong>Bregman divergence</strong> and the convexity of <span class="math notranslate nohighlight">\(f\)</span> guarantees they are non-negative for all <span class="math notranslate nohighlight">\(x,y\in\mathbb{R}^n\)</span>.</p>
<ul class="simple">
<li><p>Kullback-Leibler(KL) divergence can be expressed as a Bregman divergence using the convex function,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f_{KL}(p)=\sum_{i=1}^np_i\log p_i
\]</div>
<p><img alt="Bregman divergences" src="../_images/bregmanfun.png" /></p>
</section>
<section id="reference">
<h2><span class="section-number">2.3. </span>Reference<a class="headerlink" href="#reference" title="Link to this heading">¶</a></h2>
<p><a class="reference external" href="https://mark.reid.name/blog/meet-the-bregman-divergences.html">Meet the Bregman Divergences</a></p>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../index.html">目录</a></h3>
    <ul>
<li><a class="reference internal" href="#">2. Bregman divergence</a><ul>
<li><a class="reference internal" href="#squared-euclidean-distance">2.1. Squared Euclidean Distance</a></li>
<li><a class="reference internal" href="#bregman-divergences">2.2. Bregman divergences</a></li>
<li><a class="reference internal" href="#reference">2.3. Reference</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>上一主题</h4>
    <p class="topless"><a href="statistic_model.html"
                          title="上一章"><span class="section-number">1. </span>不确定模型</a></p>
  </div>
  <div>
    <h4>下一主题</h4>
    <p class="topless"><a href="entropy.html"
                          title="下一章"><span class="section-number">3. </span>信息熵</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/mathmodel/bregman_divergence.md.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">快速搜索</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="提交" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="总索引"
             >索引</a></li>
        <li class="right" >
          <a href="entropy.html" title="3. 信息熵"
             >下一页</a> |</li>
        <li class="right" >
          <a href="statistic_model.html" title="1. 不确定模型"
             >上一页</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Machine Learning Fundation 1.0 文档</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">2. </span>Bregman divergence</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; 版权所有 2022-2024, SSPUIIP.
      由 <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6创建。
    </div>
  </body>
</html>